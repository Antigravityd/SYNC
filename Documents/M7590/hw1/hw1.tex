\documentclass{article}

\usepackage[letterpaper]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}

\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\erf}{erf}

\title{7590 HW 1}
\author{Duncan Wilkie}
\date{?}

\begin{document}

\maketitle

I interchangeably use the $\overline{z}$ and $z^{*}$ notation for the complex conjugate.
A thousand apologies.
\section*{1a}
By the definition of the $L^2$ inner product and $A$, for any functions $f,g\in D(A)$ we have
\[\langle Af|g \rangle=\langle f|Ag \rangle\Leftrightarrow \int_0^1\overline{f''(x)}g(x)dx=\int_0^1\overline{f(x)}g''(x)dx \]
Integrating by parts,
\[\overline{f'}g\bigg|_0^1-\int_0^1\overline{f'(x)}g'(x)dx=\int_0^1\overline{f(x)}g''(x)dx\]
\[\Leftrightarrow \overline{f'}g\bigg|_0^1-\overline{f}g'\bigg|_0^1+\int_0^1\overline{f(x)}g''(x)dx=\int_0^1\overline{f(x)}g''(x)dx\]
the evaluation terms  must both be zero at $0$ and $1$ since smooth compactly-supported functions on open sets vanish
in the limit to the boundary of their domains. % TODO: proof?
Therefore, this operator is symmetric.
However, not all elements of $D(A^{\dagger})$ are elements of $D(A)$: $g\in H$ is an element of $D(A^{\dagger})$ iff there exists
$h\in H$ such that $\forall f\in D(A)$
\[
  \int_{0}^{1}\overline{f''(x)}g(x)dx=\int_{0}^{1}\overline{f(x)}h(x)dx
\]
Applying the same integration-by-parts argument as above, we may equivalently write this as
\[\Leftrightarrow \overline{f'}g\bigg|_0^1-\overline{f}g'\bigg|_0^1+\int_0^1\overline{f(x)}g''(x)dx=\int_0^1\overline{f(x)}h(x)dx\]
Since $f$ is compactly supported, $f'$ is as well, so the evaluation terms are zero by the same argument given above.
Letting $g=x^{2}$, we then have
\[\int_{0}^{1}\overline{f(x)}\cdot 2dx=\int_{0}^{1}\overline{f(x)}h(x)dx\]
from which we can clearly see the $L^{2}([0,1])$ function $h=2$ is the element adjoint to $g$ with respect to $A$.
$g$ is therefore in $D(A^{\dagger})$.
It isn't in $D(A)$ though, since $x^{2}$ doesn't vanish at 1 and therefore isn't compactly supported on this interval.
This implies $D(A^{\dagger})\neq D(A)$, so $A\neq A^{\dagger}$, i.e. $A$ isn't self-adjoint.

\section*{1b}
Proceeding similarly,
\[
  \langle Af|g \rangle=\langle f|Ag \rangle
  \Leftrightarrow \int_{0}^{1}(if'(x))^{*}g(x)dx=\int_{0}^{1}(f(x))^{*}ig'(x)dx
\]
\[
  \Leftrightarrow -if^{*}g\bigg|_{0}^{1}+\int_{0}^{1}i(f(x))^{*}g'(x)dx=\int_{0}^{1}(f(x))^{*}ig'(x)dx
\]
By the same argument as above, the evaluation term is zero, in which case the equality follows immediately.
This operator is symmetric.
Once again, $x^{2}$ is in $D^{\dagger}(A)$ but not $D(A)$: from the formula derived for $\langle Af|g \rangle$ in the proof $A$ is symmetric,
the definition of membership in $D^{\dagger}(A)$ is
\[\int_{0}^{1}(f(x))^{*}2xdx=\int_{0}^{1}(f(x))^{*}h(x)dx\]
which, choosing $h=2x\in L^{2}([0,1])$, clearly holds.
$2x$ isn't compactly supported on $(0,1)$ since it doesn't vanish in the limit to 1, so $D(A^{\dagger})\neq D(A)$ and $A$ isn't self-adjoint.

\section*{1c}
The definition of a symmetric operator is that $\forall f,g\in D(A)$
\[
  \langle Af|g \rangle= \langle f|Ag  \rangle
\]
which in this case is
\[
  \int_{\Omega}\overline{[\partial_{i}(a_{ij}(x)\partial_{j}f)(x)]}g(x)dx=\int_{\Omega}\overline{f(x)}\partial_{i}(a_{ij}(x)\partial_{j}g)(x)dx
\]
\[
  \Leftrightarrow g(x)\overline{a_{ij}(x)\partial_{j}f(x)}\bigg|_{\partial \Omega}
  -\int_{\Omega}\overline{[a_{ij}(x)\partial_{j}f(x)]}\partial_{i}g(x)dx
  =\int_{\Omega}\overline{f(x)}\partial_{i}(a_{ij}(x)\partial_{j}g)(x)dx
\]
\[
  \Leftrightarrow\overline{-a_{ij}(x)f(x)}\partial_{i}g(x)\bigg|_{\partial\Omega}
  +\int_{\Omega}\overline{f(x)}\partial_{j}\left( \overline{a_{ij}(x)}\partial_{i}g(x) \right)dx
  =\int_{\Omega}\overline{f(x)}\partial_{i}(a_{ij}(x)\partial_{j}g)(x)dx
\]
S\[
  \Leftrightarrow
  \int_{\Omega}\overline{f(x)}\partial_{i}(\overline{a_{ji}(x)}\partial_{j}g(x))dx
  =\int_{\Omega}\overline{f(x)}\partial_{i}(a_{ij}(x)\partial_{j}g)(x)dx
\]
where we have throughout used integration by parts and the same fact that functions of compact support vanish in the limit to their
boundaries.
Since $a_{ij}(x)$ is Hermitian, it is equal to $\overline{a_{ji}(x)}$, and so the two sides are equal and the operator is symmetric.
Here, $A$ is a bounded operator:
\[
  ||Af||\leq C||f||
  \Leftrightarrow \int_{\Omega}|\partial_{i}(a_{ij}(x)\partial_{j}f)(x)|^{2}dx\leq C \int_{\Omega}|f(x)|^{2}dx
\]
\[
  \Leftrightarrow \int_{\Omega}\partial_{i}a_{ij}(x)\partial_{j}f(x)dx\int_{\Omega}\overline{\partial_{i}a_{ij}(x)\partial_{j}f(x)}dx
  \leq C\int_{\Omega}|f(x)|^{2}dx
\]
\[
  \Leftrightarrow \left( f(x)\partial_{i}a_{ij}(x)\bigg|_{\partial\Omega}-\int_{\Omega}f(x)\partial_{j}\partial_{i}a_{ij}(x) \right)
  \left( \overline{f(x)\partial_{i}a_{ij}(x)}\bigg|_{\partial\Omega}-\int_{\Omega} \overline{f(x)\partial_{j}\partial_{i}a_{ij}(x)}dx \right)
  \leq C\int_{\Omega}|f(x)|^{2}dx
\]
\[
  \Leftrightarrow \int_{\Omega}\left(f(x)\overline{f(x)}\right)
  \left( [\partial_{i}\partial_{j}a_{ij}(x)]\overline{[\partial_{i}\partial_{j}a_{ij}(x)]} \right)dx
  \leq C\int_{\Omega}|f(x)|^{2}dx
\]
\[
  \Leftrightarrow \left|\int_{\Omega}f(x)\partial_{i}\partial_{j}a_{ij}(x)dx\right|^{2}\leq C\int_{\Omega}|f(x)|^{2}dx
\]
From the Cauchy-Schwartz inequality, we have
\[
  \left|\int_{\Omega}f(x)\partial_{i}\partial_{j}a_{ij}(x)dx\right|^{2}\leq \int_{\Omega}|f(x)|^{2}dx
  \int_{\Omega}|\overline{\partial_{i}\partial_{j}a_{ij}(x)}|^{2}dx
  =C\int_{\Omega}|f(x)|^{2}dx
\]
This proves the operator is bounded.
Therefore, $D(A^{\dagger})=H$, and there are certainly $L^{2}(\Omega)$ functions that aren't $C^{\infty}$, so $D(A^{\dagger})\not\subseteq D(A)$
implying $A$ is not self-adjoint.

\section*{2a}
Applying the definition of the infinitesimal generator,
\[
  Af(x)=-i\lim_{t\to 0}[f(x+vt)-f(x)]/t = -i\frac{\partial f}{\partial v}
\]
where the last equality is valid where the limit exists, using the definition of the partial derivative.
Since $V\in C^1$, and the above implies $D(A)$ is $L^2$ functions differentiable along $v$, we have $V\subseteq D(A)$, with action given above.

\section*{2b}
The adjoint of $U$ is defined by
\[
  \langle U(t)f(x) | g(x) \rangle = \langle f(x) | \left( U(t) \right)^{\dagger}g(x) \rangle
\]
The left hand side is, applying the definition of the $L^{2}$ inner product and $U$,
\[
  \langle U(t)f(x)|g(x) \rangle = \int_{\mathbb{R}^{3}} \overline{f(e^{-tB}x)}g(x)dx
\]
We can make the substitution $y=e^{-tB}x$, in which case $x=e^{tB}y$.
The component functions of this change of variables take the form
\[
  h_{i}=\sum_{n=0}^{\infty}\frac{(-t)^{n}}{n!}\left[\left(B^{n}\right)_{i1}x_{1}+\left(B^{n}\right)_{i2}x_{2}+\left(B^{n}\right)_{i3}x_{3}\right]
\]
The Jacobian of this change of coordinates is then
\[
  J=
  \begin{pmatrix}
    \frac{\partial h_{1}}{\partial x_{1}} & \frac{\partial h_{1}}{\partial x_{2}} & \frac{\partial h_{1}}{\partial x_{3}} \\
    \frac{\partial h_{2}}{\partial x_{1}} & \frac{\partial h_{2}}{\partial x_{2}} & \frac{\partial h_{2}}{\partial x_{3}} \\
    \frac{\partial h_{3}}{\partial x_{1}} & \frac{\partial h_{3}}{\partial x_{2}} & \frac{\partial h_{3}}{\partial x_{3}}
  \end{pmatrix}
  =
  \sum_{n=0}^{\infty}\frac{(-t)^{n}}{n!}
  \begin{pmatrix}
    (B^{n})_{11} & (B^{n})_{12} & (B^{n})_{13} \\
    (B^{n})_{21} & (B^{n})_{22} & (B^{n})_{23} \\
    (B^{n})_{31} & (B^{n})_{32} & (B^{n})_{33}
  \end{pmatrix}
  =e^{-tB}
\]
Using $\det e^{A}=e^{\tr A}$, the Jacobian determinant is
\[
  \det J = e^{-t\tr(B)}=1
\]
since the trace of skew-symmetric matrices is zero.
We can now finally rewrite the integral as
\[
  \int_{\mathbb{R}^{3}}\overline{f(y)}g(e^{tB}y)|\det J|dy=  \int_{\mathbb{R}^{3}}\overline{f(y)}g(e^{tB}y)dy
  =\langle f(x)|U^{\dagger}(t)g(x) \rangle
\]
which identifies $U^{\dagger}(t): g(x)\mapsto g(e^{tB}x)$.
Clearly, this is unitary:
\[
  UU^{\dagger}f(x)=f(e^{-tB}e^{tB}x)=If(x)=f(e^{tB}e^{-tB}x)=UU^{\dagger}f(x)
\]
For $f\in C^{1}(\mathbb{R}^{3})$, the infinitesimal generator acts as
\[
  Af(x)=-i\lim_{t\to 0}[f(e^{-tB}x)-f(x)]/t
\]
The numerator limits to zero, since $e^{-at}\sim1$ as $t\to 0$.
Applying L'H\^opital's rule,
\[
  =-i\lim_{t\to 0}\frac{\frac{d}{dt}f(e^{-tB}x)}{1}
  =-i\lim_{t\to 0}\left( \frac{d}{dt}e^{-tB}x \right)\cdot\nabla f(e^{-tB}x)
  =-i\lim_{t\to 0}\left(-Be^{-tB}x\right)\cdot\nabla f(e^{-tB}x)
\]
\[
  =iBx\nabla f(x)
\]
This shows that the limit exists for every $f\in C^{1}(\mathbb{R})$ (so $V\subseteq D(A)$) and gives its action.

\section*{2c} % Less sussy now :)
Notice first that the definition of $n$ and $r$ give the number $s$ ``modulo'' $2\pi$ in the sense that if one divides the real number
line into partitions by integer multiples of $2\pi$, $n(s)$ gives the multiple of $2\pi$ corresponding to the rightmost partition boundary
which lies to the left of $s$ and $r(s)$ gives the rightward displacement of $s$ from the partition boundary.
If $n$ were further left, adding $0\leq r(s)< 2\pi$ couldn't equal $s$, and if it were to the right of $s$, the same is true because $r(s)$
is positive.
We prove first that $U_{\alpha}$ is a continuous symmetry.\newline
\textit{Unitarity:}
It preserves the inner product
\[
  \langle Uf|Ug \rangle
  =\int_{0}^{2\pi}\overline{\alpha^{n(x+t)}f(r(x+t))}\alpha^{n(x+t)}g(r(x+t))dx
  =\int_{0}^{2\pi}|\alpha^{n(x+t)}|^{2}\overline{f(r(x+t))}g(r(x+t))dx
\]
Since $|\alpha|=1$, we may write $\alpha=e^{i\theta}$ in which case it is immediately clear $|\alpha^{n(x+t)}|^{2}=1$.
We now make the substitution $y=r(x+t)$, under which $dy=r'(x+t)dx\Leftrightarrow dx=\frac{dy}{r'(x+t)}$.
Differentiating the definition of $n$ and $r$ with respect to $s$ yields $1=n'(s)2\pi+r'(s)=r'(s)$ since $n$ is a step function.
Strictly speaking, it is possible there is one point in the integration interval where this derivative is not defined,
but since this is a set of measure zero it won't contribute to the integral. % sus, but not that sus
We therefore have, applying the substitution,
\[
  =\int_{r(t)}^{r(2\pi+t)}\overline{f(y)}g(y)dy=\int_{0}^{2\pi}\overline{f(y)}g(y)dy=\langle f |g\rangle
\]
where we have used for the penultimate equality the fact that $y$ (and therefore the entire integrand) has periodicity $2\pi$,
so the integral over any two intervals of length $2\pi$ will be the same.
It also is surjective, as if given a function $h\in L^{2}([0,2\pi])$, we may write since $\alpha=e^{i\theta}\Rightarrow f(x)\alpha^{g(x)}=f(x)e^{i\theta g(x)}$
\[
  h(x)=f(x)e^{ig'(x)}=f(x)\alpha^{g(x)}
\]
where $f:[0,2\pi]\to \mathbb{R}$ and $g:[0,2\pi]\to [0,2\pi]$.
For any given $h$ (which we may rewrite in the form above), $\alpha$, and $t$, one may construct the function $k\in L^{2}([0,2\pi])$
given by $k(x)=f(r(x-t))\alpha^{g(r(x-t))-n(r(x-t)+t)}$.
Noting that for $x\in[0,2\pi)$
\[r(r(x+t)-t)=r(x+t-2\pi n(x+t)-t)=r(x-2\pi n(x+t))=x\]
since
\[r(x+2k\pi)=x+2k\pi-n(x+2k\pi)=x+2k\pi-2k\pi=x\] 
by the characterization of $n(s)$ above, we have
\[
  U_{\alpha}k=\alpha^{n(x+t)}f[r(r(x+t)-t)]\alpha^{g[r(r(x+t)-t)]-n[r(r(x+t)-t)+t]}=\alpha^{n(x+t)}f(x)\alpha^{g(x)-n(x+t)}=f(x)\alpha^{g(x)}
\]
Therefore, $U_{\alpha}$ is surjective for every $\alpha$ and $t$, and in conjunction with the above result this proves $U_{\alpha}$ is
unitary.
$U_{\alpha}(0)=I$, using $x\in[0,2\pi]$:
\[
  U_{\alpha}(0)f(x)=\alpha^{n(x)}f(r(x))=\alpha^{0}f(x)=f(x)
\]
The operator behaves properly under addition in $t$:
\[
  U_{\alpha}(t+s)f(x)=\alpha^{n(x+t+s)}f(r(x+t+s))=U_{\alpha}(s)\left( \alpha^{n+t}f(r(x+t)) \right)=U_{\alpha}(s)U_\alpha(t)f(x)
\]
Lastly, using $x\in[0,2\pi)$,
\[
  \lim_{t\to 0}U_{\alpha}(t)x=\lim_{t\to 0}\alpha^{n(x+t)}r(x+t)=\alpha^{n(x)}r(x)=\alpha^{0}x=x
\]
This argument becomes slightly more subtle at $x=2\pi$ due to the discontinuities in $n$ and $r(x)$,
but since the limit must be taken from inside $[0,2\pi]$ one may use left-hand limits  $n(2\pi^{-})=0$ and $r(2\pi^{-})=2\pi$ to obtain
the same result above.\newline
The infinitesimal generator of $U_{\alpha}$ is by definition
\[
  A_{\alpha}f=-i\lim_{t\to 0}[U_{\alpha}(t)f-f]/t=-i\lim_{t\to 0}[\alpha^{n(x+t)}f(r(x+t))-f(x)]/t
\]
\[
  =-i\lim_{t\to 0}\frac{\frac{d}{dt}\alpha^{n(x+t)}f(r(x+t))}{1}=-i\lim_{t\to 0}\frac{d}{dt}{\alpha^{0}f(x+t)}=-if'(x)
\]
where we have used L'H\^opital's rule and $x\in[0,2\pi)$ (in which case the limit will become at some point exclusively through $t$ close enough to $x$ that $0\leq x+t<2\pi$, yielding $r(x+t)=x+t$ and $n(x+t)=0$).
The special case $x=2\pi$ is much the same, only the limit is taken inside $[0,2\pi]$ so only the left-hand limit is taken,
which coincides with the result above.
Functions in the given $V_{\alpha}$ make the limit above exist since they are $C^{1}$, implying $f'(x)$ is well-defined.
Therefore, $V_{\alpha}\in D(A_{\alpha})$ and the action is as given above.


\section*{3a}
The given $D(A)$ is a subset of the $V_{\alpha}$ given in problem 2c, since $C^{1}$ compactly-supported functions on $(0,2\pi)$ are a subset
of $C^{1}([0,2\pi])$ functions that vanish in the limits to $0$ and $2\pi$, which are a subset of $C^{1}([0,2\pi])$ functions where
$f(2\pi)=f(0)=0$, which are a subset of $C^{1}([0,2\pi])$ functions where $f(2\pi)=\alpha f(0)$.
Since $V_{\alpha}\subseteq D(A_{\alpha})$ was proven in 2c, we have $D(A)\subseteq D(A_{\alpha})$.
Further, $A=A_{\alpha}$ on $D(A)$ is immediate from the symbolic expression of each being identical.
This proves $A\subset A_{\alpha}$.

\section*{3b}
$A\subset A_{\alpha}$ implies that $e^{-itA_{\alpha}}=e^{-itA}$ on $D(A)$.
The theorem gives the result that
\[
  u(x,t)=e^{-itA_{\alpha}}u_{0}=U_{\alpha}(t)u_{0}(x)
\]
is the unique solution to $\dot{u}(t)=iAu(t)$ where $A$ is the infinitesimal generator of
$U(t)$.
Applying this, the result follows immediately:
\[
  u(x,t) = U(t)u_{0}(x) = U_{1}(t)u_{0}(x)=1^{n(x+t)}u_{0}(r(x+t))=u_{0}(x+t)
\]

\section*{4a}
We have, choosing a basis for which $A$ is diagonal (which exists by positive-definiteness)
\[
  Z=\int_{\mathbb{R}}e^{-\langle Ax,x  \rangle/2}dx
  =\int_{\mathbb{R}}e^{-\sum_{i=1}^{n}\lambda_{i}x_{i}^{2}/2}dx
  =\int_{\mathbb{R}}\prod_{i=1}^{n}e^{-\lambda_{i}x_{i}^{2}/2}dx
  =\prod_{i=1}^{n}\int_{\mathbb{R}^{n}}e^{-\lambda_{i}x_{i}^{2}/2}dx_{i}
\]
\[
  =\prod_{i=1}^{n}\sqrt{\frac{2\pi}{\lambda_{i}}}=\sqrt{\frac{2\pi}{\det A}}
\]
\section*{4b}
Noting that since $A$ (and therefore $G$) are Hermitian,
\[
  \langle p,Gp \rangle/2-\langle x-Gp,A(x-Gp)/2 \rangle
  =\langle p,Gp  \rangle/2-\langle x,Ax-p \rangle/2+\langle Gp,Ax-p \rangle/2
\]
\[
  =\langle p,Gp \rangle/2 - \langle x,Ax \rangle/2+\langle x,p \rangle/2+\langle Gp,Ax \rangle/2-\langle Gp,p \rangle/2
\]
\[
  =\langle p,Gp \rangle/2-\langle x,Ax\rangle/2+ \langle x,p \rangle - \langle Gp,p \rangle/2
\]
\[
  =\langle p,x \rangle-\langle Ax,x \rangle/2
\]
We can then write
\[
  \int_{\mathbb{R}^{n}}e^{\langle p,x \rangle}d\mu(x)
  =\int_{\mathbb{R}^{n}}e^{\langle p,x \rangle}\frac{1}{Z}e^{-\langle Ax,x \rangle/2}dx
  =\frac{1}{Z}\int_{\mathbb{R}^{n}}e^{\langle p,x \rangle-\langle Ax,x \rangle/2}dx
\]
as
\[
  \frac{1}{Z}\int_{\mathbb{R}^{n}}e^{\langle p,Gp \rangle/2-\langle x-Gp,A(x-Gp)/2 \rangle}dx
\]
Making the substitution $y=x-Gp$, $dy=dx$ we have
\[
  =\frac{1}{Z}\int_{\mathbb{R}^{n}}e^{\langle Gp,p \rangle/2-\langle y,Ay \rangle/2}dy
  =e^{\langle Gp,p \rangle/2}\int_{\mathbb{R}^{n}}\frac{1}{Z}e^{-\langle Ay,y \rangle/2}dy
\]
The integral is one by construction, proving the identity.

\section*{4c}
We find a similar identity:
\[
  -\langle p,Gp \rangle/2-\langle x-iGp,A(x-iGp)/2 \rangle
  =-\langle p,Gp  \rangle/2-\langle x,Ax-ip \rangle/2+\langle iGp,Ax-ip \rangle/2
\]
\[
  =-\langle p,Gp \rangle/2 - \langle x,Ax \rangle/2+\langle x,ip \rangle/2+\langle iGp,Ax \rangle/2-\langle iGp,ip \rangle/2
\]
\[
  =-\langle p,Gp \rangle/2-\langle x,Ax\rangle/2+ i\langle x,p \rangle + \langle Gp,p \rangle/2
\]
\[
  =-i\langle p,x \rangle-\langle Ax,x \rangle/2
\]
As before, this yields
\[
  \int_{\mathbb{R}^{n}}e^{i\langle p,x \rangle}d\mu(x)
  =\int_{\mathbb{R}^{n}}\frac{1}{Z}e^{-\langle p,x \rangle-\langle Ax,x \rangle/2}dx
  =\int_{\mathbb{R}^{n}}\frac{1}{Z}e^{-\langle p,Gp \rangle/2}e^{-\langle x-iGp,A(x-iGp) \rangle/2}dx
\]
\[
  =e^{-\langle p,Gp \rangle}\int_{\mathbb{R}^{n}}\frac{1}{Z}e^{-\langle y,Ay \rangle/2}dx
  =e^{-\langle p,Gp \rangle}
\]
% \section*{4d}
% The notation $\partial^{\dagger}=-\partial_{v}+\langle  Av,\cdot\rangle$ makes no sense to me; I would read it as
% ``substitute the argument of the operator as the second entry of the inner product'' but the inner product of a vector and a scalar
% (since $f:\mathbb{R}^{n}\to\mathbb{R}$) isn't a comprehensible notion.
% I will presume it means ``take the argument times the argument's argument as the second entry of the inner product,'' because this gives
% consistent results.
% We want to compute
% \[
%   \int_{\mathbb{R}^{n}}\langle v,\nabla f \rangle\frac{1}{Z}e^{-\langle Ax,x \rangle/2}dx
% \]
% There is an integration-by-parts rule that follows from the product rule for divergence the same as in one dimension:
% \[
%   \int_{\Omega}f(x) \nabla\cdot\vec{V}(x)dx=\int_{\partial \Omega}f(x)\vec{V}\cdot\hat{n}dx'-\int_{\Omega}\nabla f(x)\cdot\vec{V}dx
% \]
% We may take $\vec{V}=\frac{v}{Z}e^{-\langle Ax,x \rangle/2}$ and note our integral is the last term; if $f$ is ``nice'' enough so the
% limit of the boundary integral towards infinity vanishes, we have
% \[
%   \int_{\mathbb{R}^{n}}\langle v,\nabla f \rangle\frac{1}{Z}e^{-\langle Ax,x \rangle/2}dx
%   =\frac{1}{Z}\int_{\mathbb{R}^{n}}f(x)\nabla\cdot\left( ve^{-\langle Ax,x \rangle/2} \right)dx
% \]
% Since we may write $e^{-\langle Ax,x \rangle/2}=ve^{-\sum_{i}\lambda_{i}x_{i}^{2}/2}$,
% \[
%   \nabla\cdot ve^{-\langle Ax,x \rangle/2}=\sum_{i}-\lambda_{i}x_{i}v_{i}e^{-\sum_{i}\lambda_{i}x_{i}^{2}/2}=-\langle Ax,v \rangle
%   e^{-\langle Ax,x \rangle/2}
% \]
% yielding
% \[
%   \int_{\mathbb{R}^{n}}\langle v,\nabla f \rangle d\mu(x)=\int_{\mathbb{R}^{n}}f(x)\langle Ax,v\rangle d\mu(x)
%   =\int_{\mathbb{R}^{n}}\langle A(f(x)x),v \rangle d\mu(x)
% \]
% Making the change of variables $y=f(x)x$, the Jacobian determinant has entries $J_{ij}=\frac{\partial }{\partial x_{i}}(f(x)x_{j})$.
% For $i\neq j$, this is $J_{ij}=x_{j}\frac{\partial f}{\partial x_{i}}$

% Under the $L^{2}$ inner product,
% \[
%   \int_{\mathbb{R}^{n}}[\partial_{v}f(x)]g(x)d\mu(x)=\int_{\mathbb{R}^{n}}-f(x)\partial_{v}g(x)+f(x)\langle Av,g(x)x \rangle d\mu(x)
% \]
% \[
%   \Leftrightarrow\int_{\mathbb{R}^{n}}[\partial_{v}f(x)]g(x)d\mu(x)=-\int_{\mathbb{R}^{n}}f(x)\partial_{v}g(x)d\mu(x)
%   +\int_{\mathbb{R}^{n}}f(x)g(x)\langle Av,x\rangle d\mu(x)
% \]
% By the product rule for the gradient operator,
% \[
%   \Leftrightarrow\int_{\mathbb{R}^{n}}\partial_{v}(f(x)g(x))d\mu(x)=\int_{\mathbb{R}^{n}}f(x)g(x)\langle Av,x \rangle d\mu(x)
% \]
% By the first part of this problem, the two are equal.

% \section*{4e}
% \[
%   \int_{\mathbb{R}^{n}}\langle v,x \rangle\langle w,x \rangle d\mu(x)
%   =\int_{\mathbb{R}^{n}}\left( \sum_{i=1}^{n}v_{i}x_{i} \right)\left( \sum_{k=1}^{n}w_{k}x_{k} \right)
%   \frac{1}{Z}e^{\sum_{j=1}^{n}-\lambda_{j}x_{j}^{2}/2}dx
%   =\sum_{i=1}^{n}\sum_{k=1}^{n}\int_{\mathbb{R}^{n}}v_{i}w_{k}x_{i}x_{k}  \frac{1}{Z}e^{\sum_{j=1}^{n}-\lambda_{j}x_{j}^{2}/2}dx
% \]
% \[
%   =\sum_{i=1}^{n}\sum_{k=1}^{n}\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}v_{i}w_{k}x_{k}x_{i}e^{-(\lambda_{i} x_{i}^{2}+\lambda_{k}x_k^2)/2}dx_{i}dx_{k}
%   \left( \int_{\mathbb{R}^{n-2}}\frac{1}{Z}e^{\sum_{j\neq i,k}\lambda_{j}x_{j}^{2}/2} \right)
% \]
% When $i\neq k$, the left integrand is odd, implying the term will be zero.
% We may therefore write
% \[
%   =\sum_{i=1}^{n}\int_{\mathbb{R}^{n}}v_{i}w_{i}x_{i}^{2}\frac{1}{Z}e^{-\langle Ax,x \rangle/2}dx
% \]
% \[
%   =\sum_{i=1}^{n}\prod_{k=i}^{n}\int_{-\infty}^{\infty}v_{i}w_{i}x_{i}^{2}\frac{1}{Z}e^{-\lambda_{k}x_{k}^{2}/2}dx_{k}
% \]
% For $i\neq k$, the multiplicand is $v_{i}w_{i}x_{i}^{2}$; when $i=k$, it is equal to
% \[
%   v_{i}w_{i}\frac{1}{Z}\int_{-\infty}^{\infty}x_{i}^{2}e^{-\lambda_{i}x_{i}/2}dx_{i}
%   =v_{i}w_{i}\sqrt{\frac{\det A}{2\pi}}\sqrt{\frac{2\pi}{\lambda_{i}}}
%   =v_{i}w_{i}\sqrt{\prod_{k\neq i}\lambda_{k}}
% \]
% Thus, each term of the sum will be of the form
% \[
%   v_{i}^{n}w^{n}_{i}x_{i}^{2n-2}\sqrt{\frac{\det A}{\lambda_{i}}}
% \]
% $v_{i}w_{i}/\lambda_{i}$
% I'm unsure if there's a similar typographical error as I presumed above, but I don't think this is reducible to $\langle Gv,w \rangle$.

\section*{4f}


% \section*{7a}
% \[
%   [a(v), a^{\dagger}(w)]f=\partial_{Gv}\partial_{Gw}^{\dagger}f-\partial^{\dagger}_{Gw}\partial_{Gv}f
% \]
% \[
%   =\langle Gv, \nabla(\cdot) \rangle\circ\left( -\langle Gw,\nabla(\cdot) \rangle+\langle AGw,\cdot \rangle \right)f
%   -\left( -\langle Gw,\nabla(\cdot) \rangle+\langle AGw,\cdot \rangle \right)\circ\langle Gv,\nabla(\cdot) \rangle f
% \]
% \[
%   =\langle Gv,\nabla\left( -\langle Gw,\nabla f \rangle+\langle w,f \rangle \right) \rangle
%   -(-\langle Gw,\nabla\left( \langle Gv,\nabla f \rangle \right) \rangle+\langle w,\langle Gv,\nabla f \rangle \rangle)
% \]
% \[
%   =\langle Gv,\nabla(-\langle Gw,\nabla f \rangle) \rangle+\langle Gv,\langle w,f \rangle \rangle
%   +\langle Gw,\nabla(\langle Gv,\nabla f \rangle) \rangle
%   -\langle w,\langle Gv,\nabla f \rangle \rangle
% \]
% \[
%   =\sum_{i}\frac{v_{i}}{\lambda_{i}}\frac{\partial}{\partial x_{i}}\sum_{k}-\frac{w_{k}}{\lambda_{k}}\frac{\partial f}{\partial x_{k}}
%   +\sum_{i}\frac{v_{i}}{\lambda_{i}}\sum_{k}w_{k}f_{k}
%   +\sum_{i}\frac{w_{i}}{\lambda_{i}}\frac{\partial}{\partial x_{i}}\sum_{k}\frac{v_{k}}{\lambda_{k}}\frac{\partial f}{\partial x_{k}}
%   -\sum_{i}w_{i}\left( \sum_{k}\frac{v_{k}}{\lambda_{k}}\frac{\partial f}{\partial x_{k}}\right)_{i}
% \]
% \[
%   =-\sum_{i}\sum_{k}\frac{v_{i}w_{k}}{\lambda_{i}\lambda_{k}}\frac{\partial^{2} f}{\partial x_{i}\partial x_{k}}
%   +\sum_{i}\sum_{k}\frac{v_{i}w_{k}}{\lambda_{i}}f_{k}
%   +{\sum_{i}}\sum_{k}\frac{w_{i}v_{k}}{\lambda_{i}\lambda_{k}}\frac{\partial^{2}f}{\partial x_{i}\partial x_{k}}
%   -\sum_{i}\frac{w_{i}v_{i}}{\lambda_{i}}\frac{\partial f}{\partial x_{i}}
% \]
% \[
%   =\sum_{i}\sum_{k}\frac{v_{i}w_{k}}{\lambda_{i}}f_{k}-\sum_{i}\frac{w_{i}v_{i}}{\lambda_{i}}\frac{\partial f}{\partial x_{i}}
% \]
% \[
%   =\sum_{i}\frac{v_{i}w_{i}}{\lambda_{i}}f_{i}-\sum_{i}\frac{v_{i}}{\lambda_{i}}\sum_{k\neq i}{w_{k}}f_{k}
% \]

\section*{7b}
We can obtain a characterization of $[A^{n},B]$ as follows:
presuming an induction hypothesis $[A^{n-1},B]=(n-1)A^{n-2}C$, the commutator formula $[AB,C]=A[B,C]+[A,C]B$ gives
\[
  [A^{n},B]=A[A^{n-1},B]+ [A,B]A^{n-1}
  =A(n-1)A^{n-2}C+CA^{n-1}
  =(n-1)A^{n-1}C+A^{n-1}C
  =nA^{n-1}C
\]
This implies
\[
  e^{\lambda A}B
  =B+\lambda AB+\lambda^{2} A^{2}B/2+...
  =B+\lambda\left( BA+[A,B] \right)+\lambda^{2}(BA^{2}+[A^{2},B])/2+...
\]
\[
  =B+\lambda\left( BA+C \right)+\lambda^{2}\left( BA^{2} +2CA\right)/2+...
\]
\[
  =Be^{\lambda A}+\left( \lambda C+ \lambda^{2}CA+\lambda^{3}CA^{2}/2+... \right)
\]
\[
  =(Be^{\lambda A}+\lambda C e^{\lambda A})=(B+\lambda C)e^{\lambda A}
\]
We then compute the derivatives
\[
  \frac{d}{d\lambda}e^{\lambda (A+B)}=\frac{d}{d\lambda}\left(  1+\lambda(A+B)+\frac{\lambda^{2}}{2}(A+B)^{2}+...\right)
  =(A+B)+\lambda (A+B)^{2}+\frac{\lambda^{2}}{2}(A+B)^{3}+...
\]
\[
  =(A+B)e^{\lambda(A+B)}
\]
and
\[
  \frac{d}{d\lambda}(e^{\lambda A}e^{\lambda B}e^{-\lambda^{2}C/2})
  =Ae^{\lambda A}e^{\lambda B}e^{-\lambda^{2}C/2}+e^{\lambda A}Be^{\lambda B}e^{-\lambda^{2}C/2}
  +e^{\lambda A}e^{\lambda B}\left( -\lambda Ce^{-\lambda^{2}C/2} \right)
\]
\[
  =e^{\lambda A}e^{\lambda B}e^{-\lambda^{2}C/2}\left( A+B+\lambda C-\lambda C \right)
  =(A+B)e^{\lambda A}e^{\lambda B}e^{-\lambda^{2}C/2}
\]
Since these two functions of $\lambda$ satisfy the same differential equation and have the same value at $\lambda=0$,
they must be the same function, so for $\lambda=1$ we obtain the desired result.

% \section*{7c}
% Notice that
% \[
%   M_{f}=e^{\phi(v)}
%   \Rightarrow :e^{\phi(v)}:
%   =:e^{a(v)+a(v)^{\dagger}}:
%   =:e^{a(v)^{\dagger}+a(v)}
%   =:e^{a(v)^{\dagger}}e^{a(v)}e^{-[a(v),a(v)^{\dagger}]/2}:
%   =e^{-\langle Gv,v \rangle/2}e^{a(v)^{\dagger}}e^{a(v)}
% \]
by the result of part b.
\section*{11a}
\[
  \det \Lambda =
  \begin{vmatrix}
    \gamma & -\gamma\beta & 0 & 0 \\
    -\gamma\beta & \gamma & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{vmatrix}
  =
  1\cdot
  \begin{vmatrix}
    \gamma & -\gamma\beta & 0 \\
    -\gamma\beta & \gamma & 0 \\
    0 & 0 & 1
  \end{vmatrix}
  =
  \begin{vmatrix}
    \gamma & -\gamma\beta \\
    -\gamma\beta & \gamma
  \end{vmatrix}
  =\gamma^{2}-\gamma^{2}\beta^{2}
\]
\[
  =\gamma^{2}(1-\beta^{2})=(1-\beta^{2})^{-1}(1-\beta^{2})=1
\]
so this is a proper Lorentz transformation.
The proposed inverse satisfies
\[
  \Lambda^{-1}\Lambda=
  \begin{pmatrix}
    \gamma & \gamma\beta & 0 & 0 \\
    \gamma\beta & \gamma & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  \begin{pmatrix}
    \gamma & -\gamma\beta & 0 & 0 \\
    -\gamma\beta & \gamma & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  =
  \begin{pmatrix}
    \gamma^{2}-\gamma^{2}\beta^{2} & \gamma^{2}\beta-\gamma^{2}\beta & 0 & 0 \\
    -\gamma^{2}\beta+\gamma^{2}\beta & -\gamma^{2}\beta^{2}+\gamma^{2} & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
\]
\[
  =
  \begin{pmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  =I
\]
and
\[
  \Lambda\Lambda^{-1}=
  \begin{pmatrix}
    \gamma & -\gamma\beta & 0 & 0 \\
    -\gamma\beta & \gamma & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  \begin{pmatrix}
    \gamma & \gamma\beta & 0 & 0 \\
    \gamma\beta & \gamma & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  =
  \begin{pmatrix}
    \gamma^{2}-\gamma^{2}\beta^{2} & \gamma^{2}\beta-\gamma^{2}\beta & 0 & 0 \\
    -\gamma^{2}\beta+\gamma^{2}\beta & -\gamma^{2}\beta^{2}+\gamma^{2} & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
\]
\[
  =
  \begin{pmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  =I
\]
so it is, in fact, the inverse.
The action of the Lorentz transformation on the unit vectors along coordinate axes yields
\[\hat{x}'=\gamma \hat{x}\]
\[\hat{y}'=\hat{y}\]
\[\hat{z}'=\hat{z}\]
and so the new axes are parallel to the old.
The origin of the primed system is at $\vec{x'}=0$; this occurs at $y=0$ and $z=0$ trivially, but the $x$ variable has
\[
  -\gamma\beta t+\gamma x=0
  \Leftrightarrow x = \beta t
\]
which is exactly the origin moving along the positive $x$ axis with velocity $\beta$.

\section*{11b}
Taking the events to happen at the origin of the primed system,
\[
  \Lambda^{-1} \vec{x'}_{2}-\Lambda^{-1} \vec{x'}_{1}
  =
  \begin{pmatrix}
    \gamma t'_{2} \\
    \gamma\beta t'_{2} \\
    0 \\
    0
  \end{pmatrix}
  -
  \begin{pmatrix}
    \gamma t_{1} \\
    \gamma\beta t'_{1} \\
    0 \\
    0
  \end{pmatrix}
  =
  \begin{pmatrix}
    \gamma(t'_{2}-t'_{1}) \\
    \gamma\beta(t'_{1}-t'_{2}) \\
    0 \\
    0
  \end{pmatrix}
\]
The first component is $\gamma T$; since this is the computation of the difference between the two events in the unprimed frame,
this proves the time dilation formula.

\section*{11c}
A similar computation to the above result applies:
\[
  \Lambda^{-1}\vec{x_{2}'}-\Lambda^{-1}\vec{x_{1}'}
  =
  \begin{pmatrix}
    \gamma\beta x_{2}' \\
    \gamma x_{2}' \\
    0 \\
    0
  \end{pmatrix}
  -
  \begin{pmatrix}
    \gamma\beta x_{1}' \\
    \gamma x_{1}' \\
    0 \\
    0
  \end{pmatrix}
  =
  \begin{pmatrix}
    \gamma\beta L \\
    \gamma L \\
    0 \\
    0
  \end{pmatrix}
\]
Reading off the first component confirms the result.
Whichever occurs first along the $x$ axis occurs first in time, since $L$ is a distance and therefore positive.
For spacelike separated events,
\[
  \Lambda \vec{x_{2}}-\Lambda \vec{x_{1}}
  =
  \begin{pmatrix}
    \gamma t_{2}-\gamma\beta x_{2} - (\gamma t_{1}-\gamma\beta x_{1}) \\
    \gamma x_{2}-\gamma\beta t_{2} - (\gamma x_{1}-\gamma\beta t_{1}) \\
    0 \\
    0
  \end{pmatrix}
  =
  \begin{pmatrix}
    \gamma T-\gamma\beta L \\
    \gamma L - \gamma\beta T \\
    0 \\
    0
  \end{pmatrix}
\]
For the time component to be zero,
\[
  \gamma T=\gamma\beta L
  \Leftrightarrow \beta = \frac{T}{L}
\]
The spacelike condition ensures conformance with $|\beta|<1$:
\[
  T^{2}-L^{2}<0
  \Leftrightarrow T^{2}<L^{2}
  \Leftrightarrow |T|<|L|
  \Leftrightarrow \frac{|T|}{|L|}<1
  \Rightarrow |\beta| < 1
\]

\section*{11d}
Once again,
\[
  \Lambda^{-1}\vec{x_{2}'}-\Lambda^{-1}\vec{x_{1}'}
  =
  \begin{pmatrix}
    \gamma t_{2}+\gamma\beta x_{2}-(\gamma t_{1}+\gamma\beta x_{1}) \\
    \gamma\beta t_{2}+\gamma x_{2}-(\gamma\beta t_{1}+\gamma x_{1}) \\
    0 \\
    0
  \end{pmatrix}
  =
  \begin{pmatrix}
    \gamma T + \gamma\beta L \\
    \gamma \beta T + \gamma L \\
    0 \\
    0
  \end{pmatrix}
\]
The measurements are simultaneous in the unprimed frame, i.e. the first component of the above displacement is zero, yielding
$T=-\beta L$.
Plugging this in to the second component, one obtains
\[
  \gamma L-\gamma\beta^{2}L=L\gamma[1-\beta^{2}]=L\gamma(1/\gamma^{2})=L/\gamma
\]
as desired.

\section*{12}
For convenience of notation, define $f:SL(2,\mathbb{C})\to SO^{+}(1,3) :: A\mapsto (X\mapsto AXA^{\dagger})$ where $X$ is of the form
given in the problem.
This map is indeed a homomorphism: using $(AB)^{\dagger}=B^{\dagger}A^{\dagger}$,
\[
  f(A)f(B)=(X\mapsto AXA^{\dagger})\circ(X\mapsto BXB^{\dagger})=X\mapsto A(BXB^{\dagger})A^{\dagger}=(AB)x(B^{\dagger}A^{\dagger})
  =f(AB)
\]
The kernel of $f$ are those elements $A\in SL(2,\mathbb{C})$ such that $X=AXA^{\dagger}\Leftrightarrow A^{-1}X=XA^{\dagger}$ for all $X$ of
the given form.
Since $A\in SL(2,\mathbb{C})\Rightarrow \det A=1$ , $A$ is unitary, i.e. $AA^{\dagger}=A^{\dagger}A=I$.
We then can write
\[
  X=AXA^{\dagger}
  \Leftrightarrow XA=AXA^{\dagger}A
  \Leftrightarrow XA=AX
\]
Elements of the center of $GL(n,\mathbb{F})$ are $c^{*}I$ where $c^{*}$ is any unit of $\mathbb{F}$ and $I$ is the identity matrix, and
since the units in $\mathbb{R}$ are $\pm 1$, the kernel of the homomorphism is $\pm I$.
By the isomorphism theorem, $\im f\cong SL(2,\mathbb{C})/\ker f$, and $\ker f$ is discrete.
Since $\im f$ is a subgroup of the Lorentz group, and the Lorentz group is connected, $\im f$ is isomorphic to the whole group,
implying $f$ is surjective. % TODO: possible prove the center of GL(n,\mathbb{F}) and make sure my final argument is right

\section*{13}
Using the fact $\tilde{x}$ is the difference of two observables and therefore Hermitian,
\[
  (\Delta x)^{2}(\Delta p)^{2}
  =\langle \psi|\tilde{x}^{2}|\psi \rangle\langle \psi|\tilde{p}^{2}|\psi \rangle
  =\langle \psi|\tilde{x}^{2}\psi \rangle\langle \psi|\tilde{p}^{2}\psi \rangle
  =\langle \tilde{x}\psi|\tilde{x}\psi \rangle\langle \tilde{p}\psi|\tilde{p}\psi \rangle
  \geq |\langle \tilde{x}\psi|\tilde{p}\psi \rangle|^{2}
  =|\langle \psi|\tilde{x}\tilde{p}\psi \rangle|^{2}
  =|\langle \psi|\tilde{x}\tilde{p}|\psi \rangle|^{2}
\]
We write
\[
  \langle\psi| \tilde{x}\tilde{p}|\psi\rangle
  =\langle\psi| \left( x-\langle \psi|x|\psi \rangle \right)\left( p-\langle \psi|p|\psi \rangle \right)|\psi\rangle
  =\langle\psi|xp|\psi\rangle-\langle\psi|x\langle \psi|p|\psi \rangle|\psi\rangle-\langle\psi|p\langle \psi|x|\psi
  \rangle|\psi\rangle+\langle \psi|x|\psi \rangle\langle \psi|p|\psi \rangle\langle \psi|\psi \rangle
\]
\[
  =\langle \psi|xp|\psi \rangle+\langle \psi|x|\psi \rangle\langle \psi|p|\psi \rangle
\]
Complex numbers have the property
\[
  |z|^{2}=(\Re z)^{2}+(\Im z)^{2}\geq (\Im z)^{2} = \left( \frac{1}{2i}(z-z^{*}) \right)^{2}
\]
Applying this to $z=\langle \psi|\tilde{x}\tilde{p}|\psi \rangle$,
\[
  |\langle \psi|\tilde{x}\tilde{p}|\psi \rangle|^{2}
  \geq \left( \frac{1}{2i}\left[ (\langle \psi|xp|\psi \rangle+\langle \psi|x|\psi \rangle\langle \psi|p|\psi \rangle)
      -(\langle \psi|xp|\psi \rangle+\langle \psi|x|\psi \rangle\langle \psi|p|\psi \rangle)^{*} \right] \right)^{2}
\]
\[
  =\left( \frac{1}{2i}\left[ \langle \psi|xp|\psi\rangle-\langle \psi|px|\psi \rangle \right] \right)^{2}
  =\left( \frac{1}{2i}\langle \psi|[x,p]|\psi \rangle \right)^{2}
  =\frac{1}{4}
  =\frac{\hbar^{2}}{4}
\]
where in the last equality we have returned from natural units.
The ground state of the simple harmonic oscillator is $\psi_{0}(x)=\left( \frac{m\omega}{\pi\hbar} \right)^{1/4}e^{-m\omega x^{2}/2\hbar}$,
from which we can compute
\[
  \langle \psi_{0}|x|\psi_{0}\rangle =0\textrm{ (odd function, symmetric interval)}
\]
\[
  \langle\psi_{0}|p|\psi_{0}  \rangle=\sqrt{\frac{m\omega}{\pi\hbar}}\int_{-\infty}^{\infty}e^{-m\omega x^{2}/2\hbar}
  \left(-i\hbar\frac{\partial}{\partial x}e^{-m\omega x^{2}/2\hbar}  \right)dx
  =\sqrt{\frac{m\omega}{\pi\hbar}}\int_{-\infty}^{\infty}e^{-m\omega x^{2}/2\hbar}\left( im\omega x e^{-m\omega x^{2}/2\hbar}\right)dx
\]
\[
  =0 \textrm{ (odd function, symmetric interval)}
\]
\[
  \Rightarrow \tilde{x}=x, \tilde{p}=p
\]
\[
  \Rightarrow (\Delta x)^{2}=\langle \psi_{0}|\tilde{x}^{2}|\psi_{0} \rangle=\langle \psi_{0}|x^{2}|\psi_{0} \rangle
  =\sqrt{\frac{m\omega}{\pi\hbar}}\int_{-\infty}^{\infty}e^{-m\omega x^{2}/2\hbar}x^{2}e^{-m\omega x^{2}/2\hbar}dx
\]
\[
  =\sqrt{\frac{m\omega}{\pi\hbar}}\int_{-\infty}^{\infty}x^{2}e^{-m\omega x^{2}/\hbar}
  =\sqrt{\frac{m\omega}{\pi\hbar}}\sqrt{\frac{\pi\hbar^{3}}{4m^{3}\omega^{3}}}
  =\sqrt{\frac{\hbar^{2}}{4m^{2}\omega^{2}}}=\frac{\hbar}{2m\omega}
\]
\[
  \Rightarrow (\Delta p)^{2}=\langle \psi_{0}|\tilde{p}^{2}|\psi_{0} \rangle=\langle \psi_{0}|p^{2}|\psi_{0} \rangle
  =-\sqrt{\frac{m\omega}{\pi\hbar}}\int_{-\infty}^{\infty}e^{-m\omega x^{2}/2\hbar}\hbar^{2}\frac{\partial^{2}}{\partial x^{2}}
  e^{-m\omega x^{2}/2\hbar}dx
\]
\[
  =-\sqrt{\frac{m\omega}{\pi\hbar}}\int_{-\infty}^{\infty}e^{-m\omega x^{2}/2\hbar}
  \hbar^{2}\left( \frac{1}{\hbar^{2}} m\omega e^{-m\omega x^{2}/2\hbar}(m\omega x^{2}-\hbar)\right)dx
\]
\[
  =-\sqrt{\frac{m\omega}{\pi\hbar}}\left( m^{2}\omega^{2}\int_{-\infty}^{\infty}x^{2}e^{-m\omega x^{2}/\hbar}dx
    -\hbar m\omega\int_{-\infty}^{\infty}e^{-m\omega x^{2}/\hbar}\right)
\]
\[
  =-\sqrt{\frac{m\omega}{\pi\hbar}}\left( m^{2}\omega^{2}\sqrt{\frac{\pi \hbar^{3}}{4m^{3}\omega^{3}}}
    -\hbar m\omega\sqrt{\frac{\pi\hbar}{m\omega}} \right)
  =-(\hbar m\omega/2-\hbar m\omega)=m\omega\frac{\hbar}{2}
\]
where we have used a table for the nasty Gaussian-type integrals.
Multiplying the results, we indeed confirm this is a minimum-uncertainty state:
\[
  (\Delta x)^{2}(\Delta p)^{2}=\frac{\hbar}{2m\omega}\left( m\omega\frac{\hbar}{2}\right)=\frac{\hbar^{2}}{4}
\]

%\section*{14}
% We have
% \[
%   \langle 0|Tx(t)x(t')|0 \rangle=-\frac{\delta^{2}}{\delta J(t)\delta J(t')}Z(J)\bigg|_{J=0}
% \]
% where
% \[
%   Z(J)=\frac{\langle x't'|x,t \rangle^{J}}{\langle x'|0 \rangle\langle 0|x \rangle}
% \]
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
