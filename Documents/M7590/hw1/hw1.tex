\documentclass{article}

\usepackage[letterpaper]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}

\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\im}{im}

\title{7590 HW 1}
\author{Duncan Wilkie}
\date{?}

\begin{document}

\maketitle
I occasionally swap between physics and math conventions for complex conjugation, the inner product notation,
which arguments of the inner product are sesquillinear/linear, etc.
It's an unfortunate consequence of learning the notations simultaneously from both departments.
\section*{1a}
By the definition of the $L^2$ inner product and $A$, for any functions $f,g\in D(A)$ we have
\[\langle Af|g \rangle=\langle f|Ag \rangle\Leftrightarrow \int_0^1\overline{f''(x)}g(x)dx=\int_0^1\overline{f(x)}g''(x)dx \]
Integrating by parts,
\[\overline{f'}g\bigg|_0^1-\int_0^1\overline{f'(x)}g'(x)dx=\int_0^1\overline{f(x)}g''(x)dx\]
\[\Leftrightarrow \overline{f'}g\bigg|_0^1-\overline{f}g'\bigg|_0^1+\int_0^1\overline{f(x)}g''(x)dx=\int_0^1\overline{f(x)}g''(x)dx\]
the evaluation terms  must both be zero at $0$ and $1$ since smooth compactly-supported functions on open sets vanish
in the limit to the boundary of their domains.
Therefore, this operator is symmetric.
However, not all elements of $D(A^{\dagger})$ are elements of $D(A)$: $g\in H$ is an element of $D(A^{\dagger})$ iff there exists
$h\in H$ such that $\forall f\in D(A)$
\[
  \int_{0}^{1}\overline{f''(x)}g(x)dx=\int_{0}^{1}\overline{f(x)}h(x)dx
\]
Applying the same integration-by-parts argument as above, we may equivalently write this as
\[\Leftrightarrow \overline{f'}g\bigg|_0^1-\overline{f}g'\bigg|_0^1+\int_0^1\overline{f(x)}g''(x)dx=\int_0^1\overline{f(x)}h(x)dx\]
Since $f$ is compactly supported, $f'$ is as well, so the evaluation terms are zero by the same argument given above.
Letting $g=x^{2}$, we then have
\[\int_{0}^{1}\overline{f(x)}\cdot 2dx=\int_{0}^{1}\overline{f(x)}h(x)dx\]
from which we can clearly see the $L^{2}([0,1])$ function $h=2$ is the element adjoint to $g$ with respect to $A$.
$g$ is therefore in $D(A^{\dagger})$.
It isn't in $D(A)$ though, since $x^{2}$ doesn't vanish at 1 and therefore isn't compactly supported on this interval.
This implies $D(A^{\dagger})\neq D(A)$, so $A\neq A^{\dagger}$, i.e. $A$ isn't self-adjoint.

\section*{1b}
Proceeding similarly,
\[
  \langle Af|g \rangle=\langle f|Ag \rangle
  \Leftrightarrow \int_{0}^{1}(if'(x))^{*}g(x)dx=\int_{0}^{1}(f(x))^{*}ig'(x)dx
\]
\[
  \Leftrightarrow -if^{*}g\bigg|_{0}^{1}+\int_{0}^{1}i(f(x))^{*}g'(x)dx=\int_{0}^{1}(f(x))^{*}ig'(x)dx
\]
By the same argument as above, the evaluation term is zero, in which case the equality follows immediately.
This operator is symmetric.
Once again, $x^{2}$ is in $D^{\dagger}(A)$ but not $D(A)$: from the formula derived for $\langle Af|g \rangle$ in the proof $A$ is symmetric,
the definition of membership in $D^{\dagger}(A)$ is
\[\int_{0}^{1}(f(x))^{*}2xdx=\int_{0}^{1}(f(x))^{*}h(x)dx\]
which, choosing $h=2x\in L^{2}([0,1])$, clearly holds.
$2x$ isn't compactly supported on $(0,1)$ since it doesn't vanish in the limit to 1, so $D(A^{\dagger})\neq D(A)$ and $A$ isn't self-adjoint.

\section*{1c}
The definition of a symmetric operator is that $\forall f,g\in D(A)$
\[
  \langle Af|g \rangle= \langle f|Ag  \rangle
\]
which in this case is
\[
  \int_{\Omega}\overline{[\partial_{i}(a_{ij}(x)\partial_{j}f)(x)]}g(x)dx=\int_{\Omega}\overline{f(x)}\partial_{i}(a_{ij}(x)\partial_{j}g)(x)dx
\]
\[
  \Leftrightarrow g(x)\overline{a_{ij}(x)\partial_{j}f(x)}\bigg|_{\partial \Omega}
  -\int_{\Omega}\overline{[a_{ij}(x)\partial_{j}f(x)]}\partial_{i}g(x)dx
  =\int_{\Omega}\overline{f(x)}\partial_{i}(a_{ij}(x)\partial_{j}g)(x)dx
\]
\[
  \Leftrightarrow\overline{-a_{ij}(x)f(x)}\partial_{i}g(x)\bigg|_{\partial\Omega}
  +\int_{\Omega}\overline{f(x)}\partial_{j}\left( \overline{a_{ij}(x)}\partial_{i}g(x) \right)dx
  =\int_{\Omega}\overline{f(x)}\partial_{i}(a_{ij}(x)\partial_{j}g)(x)dx
\]
S\[
  \Leftrightarrow
  \int_{\Omega}\overline{f(x)}\partial_{i}(\overline{a_{ji}(x)}\partial_{j}g(x))dx
  =\int_{\Omega}\overline{f(x)}\partial_{i}(a_{ij}(x)\partial_{j}g)(x)dx
\]
where we have throughout used integration by parts and the same fact that functions of compact support vanish in the limit to their
boundaries.
Since $a_{ij}(x)$ is Hermitian, it is equal to $\overline{a_{ji}(x)}$, and so the two sides are equal and the operator is symmetric.
Here, $A$ is a bounded operator:
\[
  ||Af||\leq C||f||
  \Leftrightarrow \int_{\Omega}|\partial_{i}(a_{ij}(x)\partial_{j}f)(x)|^{2}dx\leq C \int_{\Omega}|f(x)|^{2}dx
\]
\[
  \Leftrightarrow \int_{\Omega}\partial_{i}a_{ij}(x)\partial_{j}f(x)dx\int_{\Omega}\overline{\partial_{i}a_{ij}(x)\partial_{j}f(x)}dx
  \leq C\int_{\Omega}|f(x)|^{2}dx
\]
\[
  \Leftrightarrow \left( f(x)\partial_{i}a_{ij}(x)\bigg|_{\partial\Omega}-\int_{\Omega}f(x)\partial_{j}\partial_{i}a_{ij}(x) \right)
  \left( \overline{f(x)\partial_{i}a_{ij}(x)}\bigg|_{\partial\Omega}-\int_{\Omega} \overline{f(x)\partial_{j}\partial_{i}a_{ij}(x)}dx \right)
  \leq C\int_{\Omega}|f(x)|^{2}dx
\]
\[
  \Leftrightarrow \int_{\Omega}\left(f(x)\overline{f(x)}\right)
  \left( [\partial_{i}\partial_{j}a_{ij}(x)]\overline{[\partial_{i}\partial_{j}a_{ij}(x)]} \right)dx
  \leq C\int_{\Omega}|f(x)|^{2}dx
\]
\[
  \Leftrightarrow \left|\int_{\Omega}f(x)\partial_{i}\partial_{j}a_{ij}(x)dx\right|^{2}\leq C\int_{\Omega}|f(x)|^{2}dx
\]
From the Cauchy-Schwartz inequality, we have
\[
  \left|\int_{\Omega}f(x)\partial_{i}\partial_{j}a_{ij}(x)dx\right|^{2}\leq \int_{\Omega}|f(x)|^{2}dx
  \int_{\Omega}|\overline{\partial_{i}\partial_{j}a_{ij}(x)}|^{2}dx
  =C\int_{\Omega}|f(x)|^{2}dx
\]
This proves the operator is bounded.
Therefore, $D(A^{\dagger})=H$, and there are certainly $L^{2}(\Omega)$ functions that aren't $C^{\infty}$, so $D(A^{\dagger})\not\subseteq D(A)$
implying $A$ is not self-adjoint.

\section*{2a}
Applying the definition of the infinitesimal generator,
\[
  Af(x)=-i\lim_{t\to 0}[f(x+vt)-f(x)]/t = -i\frac{\partial f}{\partial v}
\]
where the last equality is valid where the limit exists, using the definition of the partial derivative.
Since $V\in C^1$, and the above implies $D(A)$ is $L^2$ functions differentiable along $v$, we have $V\subseteq D(A)$, with action given above.

\section*{2b}
The adjoint of $U$ is defined by
\[
  \langle U(t)f(x) | g(x) \rangle = \langle f(x) | \left( U(t) \right)^{\dagger}g(x) \rangle
\]
The left hand side is, applying the definition of the $L^{2}$ inner product and $U$,
\[
  \langle U(t)f(x)|g(x) \rangle = \int_{\mathbb{R}^{3}} \overline{f(e^{-tB}x)}g(x)dx
\]
We can make the substitution $y=e^{-tB}x$, in which case $x=e^{tB}y$.
The component functions of this change of variables take the form
\[
  h_{i}=\sum_{n=0}^{\infty}\frac{(-t)^{n}}{n!}\left[\left(B^{n}\right)_{i1}x_{1}+\left(B^{n}\right)_{i2}x_{2}+\left(B^{n}\right)_{i3}x_{3}\right]
\]
The Jacobian of this change of coordinates is then
\[
  J=
  \begin{pmatrix}
    \frac{\partial h_{1}}{\partial x_{1}} & \frac{\partial h_{1}}{\partial x_{2}} & \frac{\partial h_{1}}{\partial x_{3}} \\
    \frac{\partial h_{2}}{\partial x_{1}} & \frac{\partial h_{2}}{\partial x_{2}} & \frac{\partial h_{2}}{\partial x_{3}} \\
    \frac{\partial h_{3}}{\partial x_{1}} & \frac{\partial h_{3}}{\partial x_{2}} & \frac{\partial h_{3}}{\partial x_{3}}
  \end{pmatrix}
  =
  \sum_{n=0}^{\infty}\frac{(-t)^{n}}{n!}
  \begin{pmatrix}
    (B^{n})_{11} & (B^{n})_{12} & (B^{n})_{13} \\
    (B^{n})_{21} & (B^{n})_{22} & (B^{n})_{23} \\
    (B^{n})_{31} & (B^{n})_{32} & (B^{n})_{33}
  \end{pmatrix}
  =e^{-tB}
\]
Using $\det e^{A}=e^{\tr A}$, the Jacobian determinant is
\[
  \det J = e^{-t\tr(B)}=1
\]
since the trace of skew-symmetric matrices is zero.
We can now finally rewrite the integral as
\[
  \int_{\mathbb{R}^{3}}\overline{f(y)}g(e^{tB}y)|\det J|dy=  \int_{\mathbb{R}^{3}}\overline{f(y)}g(e^{tB}y)dy
  =\langle f(x)|U^{\dagger}(t)g(x) \rangle
\]
which identifies $U^{\dagger}(t): g(x)\mapsto g(e^{tB}x)$.
Clearly, this is unitary:
\[
  UU^{\dagger}f(x)=f(e^{-tB}e^{tB}x)=If(x)=f(e^{tB}e^{-tB}x)=UU^{\dagger}f(x)
\]
For $f\in C^{1}(\mathbb{R}^{3})$, the infinitesimal generator acts as
\[
  Af(x)=-i\lim_{t\to 0}[f(e^{-tB}x)-f(x)]/t
\]
The numerator limits to zero, since $e^{-at}\sim1$ as $t\to 0$.
Applying L'H\^opital's rule,
\[
  =-i\lim_{t\to 0}\frac{\frac{d}{dt}f(e^{-tB}x)}{1}
  =-i\lim_{t\to 0}\left( \frac{d}{dt}e^{-tB}x \right)\cdot\nabla f(e^{-tB}x)
  =-i\lim_{t\to 0}\left(-Be^{-tB}x\right)\cdot\nabla f(e^{-tB}x)
\]
\[
  =iBx\nabla f(x)
\]
This shows that the limit exists for every $f\in C^{1}(\mathbb{R})$ (so $V\subseteq D(A)$) and gives its action.

\section*{2c} % Less sussy now :
Notice first that the definition of $n$ and $r$ give the number $s$ ``modulo'' $2\pi$ in the sense that if one divides the real number
line into partitions by integer multiples of $2\pi$, $n(s)$ gives the multiple of $2\pi$ corresponding to the rightmost partition boundary
which lies to the left of $s$ and $r(s)$ gives the rightward displacement of $s$ from the partition boundary.
If $n$ were further left, adding $0\leq r(s)< 2\pi$ couldn't equal $s$, and if it were to the right of $s$, the same is true because $r(s)$
is positive.
We prove first that $U_{\alpha}$ is a continuous symmetry.\newline
\textit{Unitarity:}
It preserves the inner product
\[
  \langle Uf|Ug \rangle
  =\int_{0}^{2\pi}\overline{\alpha^{n(x+t)}f(r(x+t))}\alpha^{n(x+t)}g(r(x+t))dx
  =\int_{0}^{2\pi}|\alpha^{n(x+t)}|^{2}\overline{f(r(x+t))}g(r(x+t))dx
\]
Since $|\alpha|=1$, we may write $\alpha=e^{i\theta}$ in which case it is immediately clear $|\alpha^{n(x+t)}|^{2}=1$.
We now make the substitution $y=r(x+t)$, under which $dy=r'(x+t)dx\Leftrightarrow dx=\frac{dy}{r'(x+t)}$.
Differentiating the definition of $n$ and $r$ with respect to $s$ yields $1=n'(s)2\pi+r'(s)=r'(s)$ since $n$ is a step function.
Strictly speaking, it is possible there is one point in the integration interval where this derivative is not defined,
but since this is a set of measure zero it won't contribute to the integral. % sus, but not that sus
We therefore have, applying the substitution,
\[
  =\int_{r(t)}^{r(2\pi+t)}\overline{f(y)}g(y)dy=\int_{0}^{2\pi}\overline{f(y)}g(y)dy=\langle f |g\rangle
\]
where we have used for the penultimate equality the fact that $y$ (and therefore the entire integrand) has periodicity $2\pi$,
so the integral over any two intervals of length $2\pi$ will be the same.
It also is surjective, as if given a function $h\in L^{2}([0,2\pi])$, we may write since $\alpha=e^{i\theta}\Rightarrow f(x)\alpha^{g(x)}=f(x)e^{i\theta g(x)}$
\[
  h(x)=f(x)e^{ig'(x)}=f(x)\alpha^{g(x)}
\]
where $f:[0,2\pi]\to \mathbb{R}$ and $g:[0,2\pi]\to [0,2\pi]$.
For any given $h$ (which we may rewrite in the form above), $\alpha$, and $t$, one may construct the function $k\in L^{2}([0,2\pi])$
given by $k(x)=f(r(x-t))\alpha^{g(r(x-t))-n(r(x-t)+t)}$.
Noting that for $x\in[0,2\pi)$
\[r(r(x+t)-t)=r(x+t-2\pi n(x+t)-t)=r(x-2\pi n(x+t))=x\]
since
\[r(x+2k\pi)=x+2k\pi-n(x+2k\pi)=x+2k\pi-2k\pi=x\] 
by the characterization of $n(s)$ above, we have
\[
  U_{\alpha}k=\alpha^{n(x+t)}f[r(r(x+t)-t)]\alpha^{g[r(r(x+t)-t)]-n[r(r(x+t)-t)+t]}=\alpha^{n(x+t)}f(x)\alpha^{g(x)-n(x+t)}=f(x)\alpha^{g(x)}
\]
Therefore, $U_{\alpha}$ is surjective for every $\alpha$ and $t$, and in conjunction with the above result this proves $U_{\alpha}$ is
unitary.
$U_{\alpha}(0)=I$, using $x\in[0,2\pi]$:
\[
  U_{\alpha}(0)f(x)=\alpha^{n(x)}f(r(x))=\alpha^{0}f(x)=f(x)
\]
The operator behaves properly under addition in $t$:
\[
  U_{\alpha}(t+s)f(x)=\alpha^{n(x+t+s)}f(r(x+t+s))=U_{\alpha}(s)\left( \alpha^{n+t}f(r(x+t)) \right)=U_{\alpha}(s)U_\alpha(t)f(x)
\]
Lastly, using $x\in[0,2\pi)$,
\[
  \lim_{t\to 0}U_{\alpha}(t)x=\lim_{t\to 0}\alpha^{n(x+t)}r(x+t)=\alpha^{n(x)}r(x)=\alpha^{0}x=x
\]
This argument becomes slightly more subtle at $x=2\pi$ due to the discontinuities in $n$ and $r(x)$,
but since the limit must be taken from inside $[0,2\pi]$ one may use left-hand limits  $n(2\pi^{-})=0$ and $r(2\pi^{-})=2\pi$ to obtain
the same result above.\newline
The infinitesimal generator of $U_{\alpha}$ is by definition
\[
  A_{\alpha}f=-i\lim_{t\to 0}[U_{\alpha}(t)f-f]/t=-i\lim_{t\to 0}[\alpha^{n(x+t)}f(r(x+t))-f(x)]/t
\]
\[
  =-i\lim_{t\to 0}\frac{\frac{d}{dt}\alpha^{n(x+t)}f(r(x+t))}{1}=-i\lim_{t\to 0}\frac{d}{dt}{\alpha^{0}f(x+t)}=-if'(x)
\]
where we have used L'H\^opital's rule and $x\in[0,2\pi)$ (in which case the limit will become at some point exclusively through $t$ close enough to $x$ that $0\leq x+t<2\pi$, yielding $r(x+t)=x+t$ and $n(x+t)=0$).
The special case $x=2\pi$ is much the same, only the limit is taken inside $[0,2\pi]$ so only the left-hand limit is taken,
which coincides with the result above.
Functions in the given $V_{\alpha}$ make the limit above exist since they are $C^{1}$, implying $f'(x)$ is well-defined.
Therefore, $V_{\alpha}\in D(A_{\alpha})$ and the action is as given above.


\section*{3a}
The given $D(A)$ is a subset of the $V_{\alpha}$ given in problem 2c, since $C^{1}$ compactly-supported functions on $(0,2\pi)$ are a subset
of $C^{1}([0,2\pi])$ functions that vanish in the limits to $0$ and $2\pi$, which are a subset of $C^{1}([0,2\pi])$ functions where
$f(2\pi)=f(0)=0$, which are a subset of $C^{1}([0,2\pi])$ functions where $f(2\pi)=\alpha f(0)$.
Since $V_{\alpha}\subseteq D(A_{\alpha})$ was proven in 2c, we have $D(A)\subseteq D(A_{\alpha})$.
Further, $A=A_{\alpha}$ on $D(A)$ is immediate from the symbolic expression of each being identical.
This proves $A\subset A_{\alpha}$.

\section*{3b}
$A\subset A_{\alpha}$ implies that $e^{-itA_{\alpha}}=e^{-itA}$ on $D(A)$.
The theorem gives the result that
\[
  u(x,t)=e^{-itA_{\alpha}}u_{0}=U_{\alpha}(t)u_{0}(x)
\]
is the unique solution to $\dot{u}(t)=iAu(t)$ where $A$ is the infinitesimal generator of
$U(t)$.
Applying this, the result follows immediately:
\[
  u(x,t) = U(t)u_{0}(x) = U_{1}(t)u_{0}(x)=1^{n(x+t)}u_{0}(r(x+t))=u_{0}(x+t)
\]

\section*{4a}
We have, choosing a basis for which $A$ is diagonal (which exists by positive-definiteness)
\[
  Z=\int_{\mathbb{R}}e^{-\langle Ax,x  \rangle/2}dx
  =\int_{\mathbb{R}}e^{-\sum_{i=1}^{n}\lambda_{i}x_{i}^{2}/2}dx
  =\int_{\mathbb{R}}\prod_{i=1}^{n}e^{-\lambda_{i}x_{i}^{2}/2}dx
  =\prod_{i=1}^{n}\int_{\mathbb{R}^{n}}e^{-\lambda_{i}x_{i}^{2}/2}dx_{i}
\]
\[
  =\prod_{i=1}^{n}\sqrt{\frac{2\pi}{\lambda_{i}}}=\sqrt{\frac{2\pi}{\det A}}
\]
\section*{4b}
Noting that since $A$ (and therefore $G$) are Hermitian,
\[
  \langle p,Gp \rangle/2-\langle x-Gp,A(x-Gp)/2 \rangle
  =\langle p,Gp  \rangle/2-\langle x,Ax-p \rangle/2+\langle Gp,Ax-p \rangle/2
\]
\[
  =\langle p,Gp \rangle/2 - \langle x,Ax \rangle/2+\langle x,p \rangle/2+\langle Gp,Ax \rangle/2-\langle Gp,p \rangle/2
\]
\[
  =\langle p,Gp \rangle/2-\langle x,Ax\rangle/2+ \langle x,p \rangle - \langle Gp,p \rangle/2
\]
\[
  =\langle p,x \rangle-\langle Ax,x \rangle/2
\]
We can then write
\[
  \int_{\mathbb{R}^{n}}e^{\langle p,x \rangle}d\mu(x)
  =\int_{\mathbb{R}^{n}}e^{\langle p,x \rangle}\frac{1}{Z}e^{-\langle Ax,x \rangle/2}dx
  =\frac{1}{Z}\int_{\mathbb{R}^{n}}e^{\langle p,x \rangle-\langle Ax,x \rangle/2}dx
\]
as
\[
  \frac{1}{Z}\int_{\mathbb{R}^{n}}e^{\langle p,Gp \rangle/2-\langle x-Gp,A(x-Gp)/2 \rangle}dx
\]
Making the substitution $y=x-Gp$, $dy=dx$ we have
\[
  =\frac{1}{Z}\int_{\mathbb{R}^{n}}e^{\langle Gp,p \rangle/2-\langle y,Ay \rangle/2}dy
  =e^{\langle Gp,p \rangle/2}\int_{\mathbb{R}^{n}}\frac{1}{Z}e^{-\langle Ay,y \rangle/2}dy
\]
The integral is one by construction, proving the identity.

\section*{4c}
We find a similar identity:
\[
  -\langle p,Gp \rangle/2-\langle x-iGp,A(x-iGp)/2 \rangle
  =-\langle p,Gp  \rangle/2-\langle x,Ax-ip \rangle/2+\langle iGp,Ax-ip \rangle/2
\]
\[
  =-\langle p,Gp \rangle/2 - \langle x,Ax \rangle/2+\langle x,ip \rangle/2+\langle iGp,Ax \rangle/2-\langle iGp,ip \rangle/2
\]
\[
  =-\langle p,Gp \rangle/2-\langle x,Ax\rangle/2+ i\langle x,p \rangle + \langle Gp,p \rangle/2
\]
\[
  =-i\langle p,x \rangle-\langle Ax,x \rangle/2
\]
As before, this yields
\[
  \int_{\mathbb{R}^{n}}e^{i\langle p,x \rangle}d\mu(x)
  =\int_{\mathbb{R}^{n}}\frac{1}{Z}e^{-\langle p,x \rangle-\langle Ax,x \rangle/2}dx
  =\int_{\mathbb{R}^{n}}\frac{1}{Z}e^{-\langle p,Gp \rangle/2}e^{-\langle x-iGp,A(x-iGp) \rangle/2}dx
\]
\[
  =e^{-\langle p,Gp \rangle}\int_{\mathbb{R}^{n}}\frac{1}{Z}e^{-\langle y,Ay \rangle/2}dx
  =e^{-\langle p,Gp \rangle}
\]

\section*{4d}
We want to compute
\[
  \int_{\mathbb{R}^{n}}\langle v,\nabla f \rangle\frac{1}{Z}e^{-\langle Ax,x \rangle/2}dx
\]
There is an integration-by-parts rule that follows from the product rule for divergence the same as in one dimension:
\[
  \int_{\Omega}f(x) \nabla\cdot\vec{V}(x)dx=\int_{\partial \Omega}f(x)\vec{V}\cdot\hat{n}dx'-\int_{\Omega}\nabla f(x)\cdot\vec{V}dx
\]
We may take $\vec{V}=\frac{v}{Z}e^{-\langle Ax,x \rangle/2}$ and note our integral is the last term; if $f$ is ``nice'' enough so the
limit of the boundary integral towards infinity vanishes, we have
\[
  \int_{\mathbb{R}^{n}}\langle v,\nabla f \rangle\frac{1}{Z}e^{-\langle Ax,x \rangle/2}dx
  =\frac{1}{Z}\int_{\mathbb{R}^{n}}f(x)\nabla\cdot\left( ve^{-\langle Ax,x \rangle/2} \right)dx
\]
Since we may write $e^{-\langle Ax,x \rangle/2}=ve^{-\sum_{i}\lambda_{i}x_{i}^{2}/2}$,
\[
  \nabla\cdot ve^{-\langle Ax,x \rangle/2}=\sum_{i}-\lambda_{i}x_{i}v_{i}e^{-\sum_{i}\lambda_{i}x_{i}^{2}/2}=-\langle Ax,v \rangle
  e^{-\langle Ax,x \rangle/2}
\]
yielding
\[
  \int_{\mathbb{R}^{n}}\langle v,\nabla f \rangle d\mu(x)=\int_{\mathbb{R}^{n}}f(x)\langle Ax,v\rangle d\mu(x)
\]
Under the $L^{2}$ inner product,
\[
  \langle \partial_{v}f,g \rangle=\int_{\mathbb{R}^{n}}[\partial_{v}f(x)]g(x)d\mu(x)
  =\int_{\mathbb{R}^{n}}\langle v,g(x)\nabla f \rangle d\mu(x)
  =\int_{\mathbb{R}^{n}}\langle v,\nabla[f(x)g(x)] \rangle d\mu(x)-\int_{\mathbb{R}^{n}}\langle v, f(x)\nabla g \rangle d\mu(x)
\]
By the result above,
\[
  =\int_{\mathbb{R}^{n}}f(x)g(x)\langle Ax,v \rangle d\mu(x)-\int_{\mathbb{R}^{n}}f(x)\langle v,\nabla g \rangle d\mu(x)
\]
\[
  =-\int_{\mathbb{R}^{n}}f(x)[\partial_{v}g(x)]d\mu(x)+\int_{\mathbb{R}^{n}}f(x)[g(x)\langle Ax,v \rangle]d\mu(x)
  =\langle f,-\partial_{v}g+g\langle A(\cdot), v  \rangle \rangle
\]
Since $A$ is positive-definite and therefore self-adjoint, and the real inner product is symmetric, this identifies $\partial^{\dagger}[f(x)]=-\partial_{v}f(x)+f(x)\langle Av,x \rangle$

\section*{4e}
\[
  \int_{\mathbb{R}^{n}}\langle v,x \rangle\langle w,x \rangle d\mu(x)
  =\int_{\mathbb{R}^{n}}\left( \sum_{i=1}^{n}v_{i}x_{i} \right)\left( \sum_{k=1}^{n}w_{k}x_{k} \right)
  \frac{1}{Z}e^{\sum_{j=1}^{n}-\lambda_{j}x_{j}^{2}/2}dx
  =\sum_{i=1}^{n}\sum_{k=1}^{n}\int_{\mathbb{R}^{n}}v_{i}w_{k}x_{i}x_{k}  \frac{1}{Z}e^{\sum_{j=1}^{n}-\lambda_{j}x_{j}^{2}/2}dx
\]
\[
  =\sum_{i=1}^{n}\sum_{k=1}^{n}\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}v_{i}w_{k}x_{k}x_{i}e^{-(\lambda_{i} x_{i}^{2}+\lambda_{k}x_k^2)/2}dx_{i}dx_{k}
  \left( \int_{\mathbb{R}^{n-2}}\frac{1}{Z}e^{\sum_{j\neq i,k}\lambda_{j}x_{j}^{2}/2} \right)
\]
When $i\neq k$, the left integrand is odd, implying the term will be zero.
We may therefore write
\[
  =\sum_{i=1}^{n}\int_{\mathbb{R}^{n}}v_{i}w_{i}x_{i}^{2}\frac{1}{Z}e^{-\langle Ax,x \rangle/2}dx
\]
\[
  =\sum_{i=1}^{n}\frac{1}{Z}\prod_{k=i}^{n}\int_{-\infty}^{\infty}v_{i}w_{i}x_{i}^{2}e^{-\lambda_{k}x_{k}^{2}/2}dx_{k}
\]
For each $i$, there is one $k=i$; we may reorder the product until the $k=i$ integral is the innermost. This integral is then equal to
$v_{i}w_{i}\sqrt{\frac{2\pi}{\lambda_{i}^{3}}}$, and the subsequent integrals each contribute $\sqrt{\frac{2\pi}{\lambda_{k}}}$;
each multiplicand is then equal to $v_{i}w_{i}\frac{1}{\lambda_{i}}\sqrt{\frac{2\pi}{\det A}}=v_{i}w_{i}\frac{1}{\lambda_{i}}Z$.
We then have
\[
  =\sum_{i}v_{i}w_{i}/\lambda_{i} = \langle Gv,w \rangle
\]

\section*{4f} % Most sussy
\[
  \int_{\mathbb{R}^{n}}e^{\langle p,x \rangle}d\mu(x)=\sum_{i=0}^{\infty}\frac{1}{i!}\int_{\mathbb{R}^{n}}\langle p,x \rangle^{i}d\mu(x)
\]
\[
  =\sum_{j=0}^{\infty}\frac{1}{j!}\langle Gp,p \rangle/2
\]
\[
  \int_{\mathbb{R}^{m}}\left( \sum_{i_{1}=1}^{m}(v_{1})_{i_{1}}x_{i_{1}}\right)\cdots\left( \sum_{i_{2n}=1}^{m}(v_{2n})_{i_{1}}x_{i_{2n}} \right)d\mu(x)
\]
\[
  =\sum_{i_{1}=1}^{m}\cdots\sum_{i_{2n}=1}^{m}\int_{\mathbb{R}^{m}}(v_{1})_{j}x_{i_{1}}(v_{2})_{j}x_{i_{2}}\cdots (v_{2n})_{j}x_{i_{2n}}d\mu(x)
\]
\[
  =\sum\langle v_{i_{1}},v_{j_{1}}  \rangle\langle v_{i_{2}},v_{j_{2}} \rangle\cdots \langle v_{i_{n}},v_{j_{n}} \rangle
  \int_{\mathbb{R}^{m}}\sum_{i_{1}=1}^{m}\cdots \sum_{i_{2n}=1}^{m}x_{i^{1}}\cdots x_{i^{2n}}d\mu(x)
\]
\[
  =\sum\langle v_{i_{1}},v_{j_{1}}  \rangle\langle v_{i_{2}},v_{j_{2}} \rangle\cdots \langle v_{i_{n}},v_{j_{n}} \rangle
  \int_{\mathbb{R}^{m}}\langle x,x \rangle^{n} d\mu(x)
\]
\[
  =\sum\langle v_{i_{1}},v_{j_{1}}  \rangle\langle v_{i_{2}},v_{j_{2}} \rangle\cdots \langle v_{i_{n}},v_{j_{n}} \rangle
  \int_{\mathbb{R}^{n}}
\]
% \[
%   \prod_{i=1}^{2n}\langle v_{i},x \rangle=\prod_{i=1}^{2n}\sum_{j=1}^{n}(v_{i})_{j}x_{j}
%   =\sum_{i=1}^{n}\sum_{j=1}^{n}\sum_{k=1}^{n}x_{i}^{k}
% \]
% can be seen to hold by multiplying by $\langle v_{i+1},x \rangle=\sum_{l=1}^{n}(v_{i+1})_{l}x_{l}$

% Presume for induction that the given theorem holds.
% Then
% \[
%   \int_{\mathbb{R}^{n}}\left(\prod_{i=1}^{2n}\langle v_{i},x \rangle\right)\langle v_{2n+1},x \rangle\langle v_{2n+2},x \rangle d\mu(x)
%   =\int_{\mathbb{R}^{n}}\left(\prod_{i=1}^{2n}\langle v_{i},x \rangle\right)\langle v_{2n+1},x \rangle
%   \left( \sum_{i=1}^{n}(v_{2n+2})_{i}x_{i} \right)d\mu(x)
% \]
% \[
%   =
% \]
% \[
%   \int_{\mathbb{R}^{n}}\left( \prod_{i=1}^{2n}\langle v_{i},x \rangle\right)
%   \left( \sum_{i=1}^{n}\sum_{j=1}^{n}(v_{2n+1})_{i}x_{i}(v_{2n+2})_{j}x_{j} \right)d\mu(x)
%   =\int_{\mathbb{R}^{n}}\left( \prod_{i=1}^{2n}\langle v_{i},x \rangle\right)\langle v_{2n+1},v_{2n+2} \rangle\langle  x,x \rangle d\mu(x)
% \]
% \[
%   =\langle v_{2n+1},v_{2n+2} \rangle\int_{\mathbb{R}^{n}}\left( \prod_{i=1}^{2n}\langle v_{i},x \rangle \right)\left( \sum_{i}x_{i}^{2}\right)
%   \prod_{k}e^{-\lambda_{k}x_{k}^{2}/2}dx
% \]
% \[
%   \sum_{k+}
% \]
% \[
%   \sum_{i=1}^{n}\sum_{j=1}^{n}\int_{\mathbb{R}^{n}}\left( \prod_{i=1}^{2n}\langle v_{i},x \rangle \right)v_{2n+1}v_{2n+2}x_{i}x_{j}d\mu(x)
% \]
% As above, when $i\neq j$ the summand is a product of $n$ integrals, two of which are of odd functions, and the rest of which are of
% even functions.
% Such summands will then be zero, implying
% \[
%   =\sum_{i=1}^{n}\int_{\mathbb{R}^{n}}\left( \prod_{i=1}^{2n}\langle v_{i},x\rangle \right)(v_{2n+1})_{i}(v_{2n+2})_{i}x_{i}^{2}d\mu(x)
% \]
% \[
%   =\sum_{i=1}^{n}\int_{\mathbb{R}^{n}}\left( \prod_{i=1}^{2n}\sum_{k=1}^{n}(v_{i})_{k}x_{k} \right)
% \]
\section*{4g}
If $F(x)=\sum_{l=1}^{a}\beta_{l}e^{i\sum_{k}\alpha_{k}\langle v_{k},x \rangle}$ and
$H(x)=\sum_{j=1}^{b}\gamma_{j} e^{i\sum_{m}\epsilon_{m}\langle w_{m},x \rangle}$, then
\[
  \int_{\mathbb{R}^{n}}F(x)H(x)d\mu(x)=\sum_{l=1}^{a}\sum_{j=1}^{b}\beta_{l}\gamma_{j}
  \int_{\mathbb{R}^{n}}e^{i\sum_{k,m=0}^{a,b}\alpha_{k}\langle v_{k},x \rangle+\epsilon_{m}\langle w_{m},x\rangle} d\mu(x)
\]
Using
\[
  \sum_{k,m}\alpha_{k}\langle v_{k}x \rangle+\epsilon_{m}\langle w_{m},x \rangle=\sum_{k,m}\langle \alpha_{k}v_{k}+\epsilon_{m}w_{m},x\rangle
  =\langle \sum_{k,m}\alpha_{k}v_{k}+\epsilon_{m}w_{m},x \rangle
\]
and part c,
\[
  =\sum_{l}\sum_{j}\beta_{l}\gamma_{j}e^{-\langle G\sum_{k,m}\alpha_{k}v_{k}+\epsilon_{m}w_{m}, \sum_{k,m}\alpha_{k}v_{k}+\epsilon_{m}w_{m}\rangle/2}
\]
\[
  =\sum_{l}\sum_{j}\beta_{l}\gamma_{j}e^{-\langle \sum_{k,m}\alpha_{k}Gv_{k}+\epsilon_{m}Gw_{m},\sum_{p,q}\alpha_{p}v_{p}+\epsilon_{q}w_{q} \rangle/2}
\]
\[
  =\sum_{l}\sum_{j}\beta_{l}\gamma_{j}e^{-(\sum_{k,m}\sum_{p,q}\alpha_{k}\alpha_{p}\langle Gv_{k},v_{p}  \rangle
    +\epsilon_{m}\alpha_{p}\langle Gw_{m},v_{p} \rangle+\epsilon_{m}\epsilon_{q}\langle Gw_{m},w_{q} \rangle)/2}
\]
By the given orthogonality data,
\[
  =\sum_{l}\sum_{j}\beta_{l}\gamma_{j}e^{-(\sum_{k,m}\sum_{p,q}\alpha_{k}\alpha_{p}\langle Gv_{k},v_{p} \rangle+\epsilon_{m}\epsilon_{q}\langle Gw_{m},w_{q} \rangle)/2}
\]
Similarly,
\[
  \int_{\mathbb{R}^{n}}F(x)d\mu(x)\int_{\mathbb{R}^{n}}H(x)d\mu(x)
  =\int_{\mathbb{R}^{n}}\sum_{l}\beta_{l}e^{i\sum_{k}\alpha_{k}\langle v_{k} ,x\rangle}d\mu(x)
  \int_{\mathbb{R}^{n}}\sum_{j}\gamma_{j}e^{i\sum_{m}\epsilon_{m}\langle w_{m},x \rangle}
\]
\[
  =\sum_{l}\sum_{j}\beta_{l}e^{-\langle G\sum_{k}\alpha_{k}v_{k},\sum_{p}\alpha_{p}v_{p}\rangle/2}
  \gamma_{j}e^{-\langle G\sum_{m}\epsilon_{m} w_{m},\sum_{q}\epsilon_{q}w_{q} \rangle/2}
\]
\[
  =\sum_{l}\sum_{j}\beta_{l}\gamma_{j}e^{-\sum_{km}\sum_{pq}\alpha_{k}\alpha_{p}\langle Gv_{k},v_{p} \rangle/2
    -\epsilon_{m}\epsilon_{q}\langle Gw_{m},w_{q} \rangle/2}
\]
Therefore, these expressions are equal.

\section*{5} % first part wrong cause gradient variables
\[
  \frac{\partial}{\partial t}\int_{\mathbb{R}^{n}}f(x+t^{1/2}y)d\mu(y)=\int_{\mathbb{R}^{n}}\frac{1}{2}\frac{y}{\sqrt{t}}\cdot\nabla f d\mu(y)
\]
Integrating by parts,
\[
  =\int_{\mathbb{R}^{n}}f(x+t^{1/2}y)\nabla\cdot \left(\frac{1}{2}\frac{y}{\sqrt{t}}\frac{1}{Z}e^{-\langle Ay,y \rangle/2}\right)dy
  =\frac{1}{2Z\sqrt{t}}\int_{\mathbb{R}^{n}}\sum_{i=1}^{n}f(x+t^{1/2}y)\frac{\partial}{\partial y_{i}}y_{i}e^{-\sum_{j=1}^{n}\lambda_{j}y_{j}^{2}/2}dy
\]
\[
  =\frac{1}{2Z\sqrt{t}}\sum_{i=1}^{n}\int_{\mathbb{R}^{n}}f(x+t^{1/2}y)\left( e^{-\sum_{j=1}^{n}\lambda_{j}y_{j}^{2}/2}
  -\lambda_{i}y_{i}^{2}e^{-\sum_{j=1}^{n}\lambda_{j}y_{j}^{2}/2}\right)dy
\]
\[
  =\frac{1}{2\sqrt{t}}\left( \int_{\mathbb{R}^{n}}f(x+t^{1/2}y)d\mu(y)-\int_{\mathbb{R}^{n}}f(x+t^{1/2}y)\langle Ay,y \rangle d\mu(y)\right)
\]
We also have, choosing a basis in which $G_{ij}$ is diagonal as we've been doing the whole section,
\[
  L\int_{\mathbb{R}^{n}}f(x+t^{1/2}y)d\mu(y)=\frac{1}{2}\sum_{i=1}^n\frac{1}{\lambda_{i}}\partial_{i}^{2}\int_{\mathbb{R}^{n}}f(x+t^{1/2}y)d\mu(y)
\]
\[
  =\frac{1}{2}\sum_{i=1}^{n}\frac{1}{\lambda_{i}}\int_{\mathbb{R}^{n}}\frac{\partial^{2}}{\partial x_{i}^{2}}
  f(x+t^{1/2}y)\frac{1}{Z}e^{-\sum_{j=1}^{n}\lambda_{j}y_{j}^{2}}dy
  =\frac{1}{2}\sum_{i=1}^{n}\frac{1}{\lambda_{i}}\int_{\mathbb{R}^{n}}
  f_{x_{i}x_{i}}(x+t^{1/2}y)\frac{1}{Z}e^{-\sum_{j=1}^{n}\lambda_{j}y_{j}^{2}}dy
\]
I presume from this point there will be some change of variables (with a Jacobian that gives the factor of $\frac{1}{\sqrt{t}}$) that
allows one to integrate out the partial derivatives by parts, which will pull down $\lambda_{i}^{2}y_{i}^{2}$ from the exponent and recover
the expression above.

\section*{6a}
\[
  e^{-L}p(x)=\int_{\mathbb{R}^{n}}p(x+iy)d\mu(y)
  =\int_{\mathbb{R}^{n}}\sum_{j=1}^{m}a_{j}(x+iy)^{j}d\mu(y)
\]
\[
  =\sum_{j=1}^{m}a_{j}\int_{\mathbb{R}^{n}}(x+iy)^{j}d\mu(y)
  =\sum_{j=1}^{m}a_{j}\int_{\mathbb{R}^{n}}\sum_{k=0}^{j}\binom{j}{k}x^{k}(iy)^{j-k}d\mu(y)
\]
\[
  =\sum_{j=1}^{m}\sum_{k=0}^{j}a_{j}\binom{j}{k}x^{k}(i)^{j-k}\int_{\mathbb{R}^{n}}y^{j-k}d\mu(y)
\]
\[
  =\sum_{j=1}^{m}\sum_{k=0}^{j}a_{j}\binom{j}{k}x^{k}(i)^{j-k}\frac{1}{Z}\prod_{p=1}^{n}\int_{\mathbb{R}^{n}}y_p^{j-k}e^{-\lambda_{p}x_{p}^{2}/2}dx_{p}
\]
For $j-k$ odd, the integral is zero (meaning the imaginary unit disappears, which is good).
The integral certainly exists for each $y^{j-k}$, so we're done in principle: this formula gives a well-defined function
$f:\mathbb{R}^{n}\to \mathbb{R}$ for arbitrary $a_{j}$ determining any given polynomial.
For completeness, a CAS computation of the integral yields
\[
  =\sum_{j=1}^{m}\sum_{k=0}^{j}(j-k+1\mod{2})a_{j}\binom{j}{k}x^{k}(-1)^{j-k}\frac{1}{Z}\prod_{p=1}^{n}\left( \frac{\lambda_{p}}{2} \right)^{-(j-k+1)/2}
  \Gamma([j-k+1]/2)
\]
\[
  =\sum_{j=1}^{m}\sum_{k=0}^{j}(j-k+1\mod{2})a_{j}\binom{j}{k}x^{k}(-1)^{j-k}\frac{(\det A)^{-(j-k+1)/2}}{Z}
  \left( \frac{\Gamma([j-k+1]/2)}{2} \right)^{-(j-k+1)/2}
\]
For the exponential, we may employ the analytic continuation from 4c:
\[
  :e^{\langle p,x \rangle}:=\int_{\mathbb{R}^{n}}e^{\langle p,x+iy\rangle}d\mu(y)
  =e^{\langle p,x \rangle}\int_{\mathbb{R}^{n}}e^{i\langle p,y  \rangle}d\mu(x)
  =e^{\langle p,x \rangle-\langle Gp,p \rangle/2}
\]
As this is a function $f:\mathbb{R}^{n}\to \mathbb{R}$, the normal ordering exists and is equal to the above.

\section*{6b}
\[
  \int_{\mathbb{R}^{m}}\langle v_{1},x+iy \rangle\cdots\langle v_{m},x+iy \rangle
\]
\[
  \langle v_{1},x \rangle\cdots\langle v_{m},x \rangle=\prod_{i=1}^{m}\sum_{j=1}^{m}(v_{i})_{j}x_{j}
\]
\[
  \Rightarrow e^{-L}\langle v_{1},x \rangle\cdots\langle v_{m},x \rangle
  =\sum_{k=0}^{\infty}\frac{(-1)^{k}}{2^{k}k!}\left( \sum_{l=1}^{m}\frac{1}{\lambda_{l}}\partial_{l}^{2} \right)^{k}
  \prod_{i=1}^{m}\sum_{j=1}^{m}(v_{i})_{j}x_{j}
\]
For $k>0$, this is zero, since a differential operator with degree two acting on $x_{j}$ will always yield zero, so
\[
  =\prod_{i=1}^{m}\sum_{j=1}^{m}(v_{i})_{j}x_{j}
  =\langle v_{1},x \rangle\cdots\langle v_{m},x \rangle
\]
We have
\[
  (:e^{\alpha_{i}\langle v_{i},x \rangle}:)_{i}=\int_{\mathbb{R}^{n}}e^{\alpha_{i}\langle v_{i},x+iy \rangle}d\mu(y)
  =e^{\alpha_{i}\langle v_{i},x \rangle}\int_{\mathbb{R}^{n}}e^{i\langle \alpha_{i}v_{i}, y\rangle}d\mu(y)
\]
\[
  =e^{\langle \alpha_{i}v_{i},x\rangle}e^{-\langle G\alpha_{i}v_{i},\alpha_{i}v_{i} \rangle}
  =e^{\alpha_{i}\langle v_{i},x \rangle-\alpha_{i}^{2}\langle Gv_{i},v_{i}  \rangle}
  =e^{\alpha_{i}\sum_{k=1}^{m}v_{k}x_{k}-\alpha_{i}^{2}\sum_{j=1}^{m}v_j^{2}/\lambda_{j}}
\]
\[
  \Rightarrow \partial_{\alpha_{1}}\cdots\partial_{\alpha_{m}}:e^{\alpha_{i}\langle v_{i},x \rangle}:
  =\prod_{i=1}^{m}\left(\sum_{k=1}^{m}v_{k}x_{k}-2\alpha_{i}\sum_{j=1}^{m}v_{j}^{2}\right)
  e^{\alpha_{i}\sum_{k=1}^{m}v_{k}x_{k}-\alpha_{i}^{2}\sum_{j=1}^{m}v_j^{2}/\lambda_{j}}
\]
Taking $\alpha_{i}=0$,
\[
  =\prod_{i=1}^{m}\sum_{k=1}^{m}v_{k}x_{k}
\]
It should be noted I am somewhat suspicious of this result as what the problem means by $\alpha$ isn't fully clear.

\section*{6c}
Writing $f=e^{L}g$,
\[
  \partial_{v}:e^{L}g:=\partial_{v}e^{-L}e^{L}g=\partial_{v}g=\langle v,\nabla g \rangle
\]
\[
  :\partial_{v}e^{L}g:=e^{-L}\partial_{v}e^{L}g=e^{L}\langle v,\nabla e^{-L}g \rangle=\langle v, \nabla e^{L}e^{-L}g  \rangle
  =\langle v,\nabla g \rangle
\]
where we have used commutativity of partial derivatives of analytic functions for the penultimate step.

\section*{6d}
For clarity, we write
\[
  [e^{tL},M_{\langle v,\cdot \rangle}]f(x)=\left( e^{tL}M_{\langle v,x \rangle}-M_{\langle v,x \rangle}e^{tL}\right)f(x)
 =e^{tL}\langle v,x \rangle f(x)-\langle v,x \rangle e^{tL}f(x)
\]
Differentiating,
\[
  \frac{d}{dt}[e^{tL},M_{\langle v,\cdot \rangle}]f(x)=Le^{tL}\langle v,x \rangle f(x)-\langle v,x\rangle Le^{tL}f(x)
  =e^{tL}\langle v,x \rangle Lf(x)-\langle v,x \rangle e^{tL}Lf(x)+e^{tL}|v|f(x)
\]
\[
  =\left( [e^{tL},M_{\langle v,\cdot \rangle}]L+e^{tL}|v|\right)f(x)
\]
\[
  \frac{d^{2}}{dt^{2}}=\left[ e^{tL},M_{\langle v,\cdot \rangle}\right]L^{2}+2Le^{tL}|v|f(x)
\]
and
\[
  \frac{d}{dt} te^{tL}\partial_{Gv}=tLe^{tL}\partial_{Gv}+e^{tL}\partial_{Gv}
\]
\[
  \frac{d^{2}}{dt^{2}}te^{tL}\partial_{Gv}=tL^{2}e^{tL}\partial_{Gv}+2Le^{tL}\partial_{Gv}
\]
Both equations satisfy
\[
  \frac{d^{2}O}{dt^{2}}=\left(2\frac{dO}{dt}-O\right)L
\]
and are equal to zero at $t=0$.
Therefore, by uniqueness of ODE solutions, they are equal.

\section*{6e}
We have by the last part
\[
  [e^{tL},M_{\langle v,\cdot \rangle}]f(x)=e^{tL}\langle v,x \rangle f(x)-\langle v,x \rangle e^{tL}f(x)
  \Rightarrow e^{tL}\langle v,x \rangle f(x)=\langle v,x  \rangle e^{tL}f(x) +te^{tL}\partial_{Gv}f(x)
\]
Taking $t=-1$,
\[
  :\langle v,x \rangle f(x): = \langle v,x \rangle :f: -:\partial_{Gv}f(x):
\]
By part c,
\[
  :\langle v,x \rangle f(x): =  \langle v,x \rangle :f: -\partial_{Gv}:f:
\]
as desired.

\section*{6f}
I suspect another typo here. This seems like a robust result to me, but it's wildly inconsistent with the rest of this problem,
not to mention it making zero intuitive sense.
\[
  :f:=:\prod_{i=1}^{n+1}\langle v_{i},x \rangle:=\prod_{i=1}^{n+1}\partial_{Gv_{i}}^{\dagger}
  =\prod_{i=1}^{n+1}-\langle Gv_{i},\nabla 1 \rangle+\langle v_{i},x \rangle
  =\prod_{i=1}^{n+1}\langle v_{i},x \rangle
\]

\section*{7a}
\[
  [a(v), a^{\dagger}(w)]f(x)
  =\partial_{Gv}\partial_{Gw}^{\dagger}f(x)-\partial^{\dagger}_{Gw}\partial_{Gv}f(x)
\]
\[
  =\partial_{Gv}\left( -\partial_{Gw}f(x)+f(x)\langle AGw,x \rangle \right)
  +\partial_{Gw}[\partial_{Gv}f(x)]-[\partial_{Gv}f(x)]\langle AGw,x  \rangle
\]
\[
  =-\partial_{Gv}\partial_{Gw}f(x)+\partial_{Gv}[f(x)\langle w,x\rangle]+\partial_{Gw}\partial_{Gv}f(x)-[\partial_{Gv}f(x)]\langle w,x \rangle
\]
\[
  =-\langle Gv,\nabla\langle Gw,\nabla f \rangle \rangle+\langle Gv,\nabla[f(x)\langle w,x \rangle] \rangle
  +\langle Gw,\nabla\langle Gv,\nabla f \rangle \rangle-\langle Gv,\nabla f(x)\rangle\langle w,x \rangle
\]
Noting that $\nabla\langle v,\nabla f(x) \rangle=\nabla\sum_{i=1}^{n}v_{i}\frac{\partial f}{\partial x_{i}}
=\sum_{i=1}^{n}v_{i}\frac{\partial^{2}f}{\partial x_{i}^{2}}\hat{x}_{i}=\langle v,\nabla^{2}f \rangle$,
\[
  =-\langle Gv,\langle Gw,\nabla^{2}f \rangle \rangle+\langle Gv,\langle w,x \rangle\nabla f+f(x)\langle w,\nabla x \rangle \rangle
  +\langle Gw,\langle Gv,\nabla^{2}f \rangle \rangle-\langle Gv,\nabla f(x)\rangle\langle w,x \rangle
\]
\[
  =-\langle Gw,\langle Gv,\nabla^{2}f \rangle  \rangle+\langle Gv,\langle w,x \rangle\nabla f \rangle+\langle Gv,f(x)w \rangle
  +\langle Gw,\langle Gv,\nabla^{2}f \rangle \rangle-\langle Gv,\nabla f(x)\rangle\langle w,x \rangle
\]
\[
  =\langle Gv,f(x)w \rangle
\]
\[
  =f(x)\langle Gv,w \rangle
\]
as desired.
\section*{7b}
We can obtain a characterization of $[A^{n},B]$ as follows:
presuming an induction hypothesis $[A^{n-1},B]=(n-1)A^{n-2}C$, the commutator formula $[AB,C]=A[B,C]+[A,C]B$ gives
\[
  [A^{n},B]=A[A^{n-1},B]+ [A,B]A^{n-1}
  =A(n-1)A^{n-2}C+CA^{n-1}
  =(n-1)A^{n-1}C+A^{n-1}C
  =nA^{n-1}C
\]
This implies
\[
  e^{\lambda A}B
  =B+\lambda AB+\lambda^{2} A^{2}B/2+...
  =B+\lambda\left( BA+[A,B] \right)+\lambda^{2}(BA^{2}+[A^{2},B])/2+...
\]
\[
  =B+\lambda\left( BA+C \right)+\lambda^{2}\left( BA^{2} +2CA\right)/2+...
\]
\[
  =Be^{\lambda A}+\left( \lambda C+ \lambda^{2}CA+\lambda^{3}CA^{2}/2+... \right)
\]
\[
  =(Be^{\lambda A}+\lambda C e^{\lambda A})=(B+\lambda C)e^{\lambda A}
\]
We then compute the derivatives
\[
  \frac{d}{d\lambda}e^{\lambda (A+B)}=\frac{d}{d\lambda}\left(  1+\lambda(A+B)+\frac{\lambda^{2}}{2}(A+B)^{2}+...\right)
  =(A+B)+\lambda (A+B)^{2}+\frac{\lambda^{2}}{2}(A+B)^{3}+...
\]
\[
  =(A+B)e^{\lambda(A+B)}
\]
and
\[
  \frac{d}{d\lambda}(e^{\lambda A}e^{\lambda B}e^{-\lambda^{2}C/2})
  =Ae^{\lambda A}e^{\lambda B}e^{-\lambda^{2}C/2}+e^{\lambda A}Be^{\lambda B}e^{-\lambda^{2}C/2}
  +e^{\lambda A}e^{\lambda B}\left( -\lambda Ce^{-\lambda^{2}C/2} \right)
\]
\[
  =e^{\lambda A}e^{\lambda B}e^{-\lambda^{2}C/2}\left( A+B+\lambda C-\lambda C \right)
  =(A+B)e^{\lambda A}e^{\lambda B}e^{-\lambda^{2}C/2}
\]
Since these two functions of $\lambda$ satisfy the same differential equation and have the same value at $\lambda=0$,
they must be the same function, so for $\lambda=1$ we obtain the desired result.

\section*{7c}
Notice that by part a $[a(v),a(v)^{\dagger}]$ commutes with both $a$ and $a^{\dagger}$ since it's a scalar.
We then have
\[
  M_{f}=e^{\phi(v)}=e^{a(v)+a^{\dagger}(v)}=e^{a^{\dagger}(v)+a(v)}=e^{a^{\dagger}(v)}e^{a(v)}e^{-[a^{\dagger}(v),a(v)]/2}
  =e^{\langle Gv,v\rangle/2}e^{a^{\dagger}(v)}e^{a(v)}
\]
The normal ordering $:M_{f}:$ is $e^{a^{\dagger}(v)}e^{a(v)}$, so
\[
  M_{f}/:M_{f}:=e^{\langle Gv,v \rangle/2} \Rightarrow :M_{f}:=e^{-\langle Gv,v  \rangle/2}M_{f}
\]
We also have from a previous problem the analytic normal ordering
\[
  :e^{\langle v,x \rangle}:=e^{\langle p,x \rangle-\langle Gv,v \rangle/2}
\]
which indeed confirms $:M_{f}:=M_{:f:}$ in this case.
If all $f$ are sufficiently ``nice,'' they may be represented by a $\mathbb{C}$-linear combination of exponential functions of this form.
This result therefore generalizes, since $:M_{f}+M_{g}:=:M_{f}:+:M_{g}$ and $:\alpha M_{f}:=\alpha :M_{f}$, implying
$:\sum_{i}\alpha_{i}M_{f}:=\sum_{i}\alpha_{i}:M_{f}:$ for $:M_{f}:$ of the form above.
\section*{11a}
\[
  \det \Lambda =
  \begin{vmatrix}
    \gamma & -\gamma\beta & 0 & 0 \\
    -\gamma\beta & \gamma & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{vmatrix}
  =
  1\cdot
  \begin{vmatrix}
    \gamma & -\gamma\beta & 0 \\
    -\gamma\beta & \gamma & 0 \\
    0 & 0 & 1
  \end{vmatrix}
  =
  \begin{vmatrix}
    \gamma & -\gamma\beta \\
    -\gamma\beta & \gamma
  \end{vmatrix}
  =\gamma^{2}-\gamma^{2}\beta^{2}
\]
\[
  =\gamma^{2}(1-\beta^{2})=(1-\beta^{2})^{-1}(1-\beta^{2})=1
\]
so this is a proper Lorentz transformation.
The proposed inverse satisfies
\[
  \Lambda^{-1}\Lambda=
  \begin{pmatrix}
    \gamma & \gamma\beta & 0 & 0 \\
    \gamma\beta & \gamma & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  \begin{pmatrix}
    \gamma & -\gamma\beta & 0 & 0 \\
    -\gamma\beta & \gamma & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  =
  \begin{pmatrix}
    \gamma^{2}-\gamma^{2}\beta^{2} & \gamma^{2}\beta-\gamma^{2}\beta & 0 & 0 \\
    -\gamma^{2}\beta+\gamma^{2}\beta & -\gamma^{2}\beta^{2}+\gamma^{2} & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
\]
\[
  =
  \begin{pmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  =I
\]
and
\[
  \Lambda\Lambda^{-1}=
  \begin{pmatrix}
    \gamma & -\gamma\beta & 0 & 0 \\
    -\gamma\beta & \gamma & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  \begin{pmatrix}
    \gamma & \gamma\beta & 0 & 0 \\
    \gamma\beta & \gamma & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  =
  \begin{pmatrix}
    \gamma^{2}-\gamma^{2}\beta^{2} & \gamma^{2}\beta-\gamma^{2}\beta & 0 & 0 \\
    -\gamma^{2}\beta+\gamma^{2}\beta & -\gamma^{2}\beta^{2}+\gamma^{2} & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
\]
\[
  =
  \begin{pmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  =I
\]
so it is, in fact, the inverse.
The action of the Lorentz transformation on the unit vectors along coordinate axes yields
\[\hat{x}'=\gamma \hat{x}\]
\[\hat{y}'=\hat{y}\]
\[\hat{z}'=\hat{z}\]
and so the new axes are parallel to the old.
The origin of the primed system is at $\vec{x'}=0$; this occurs at $y=0$ and $z=0$ trivially, but the $x$ variable has
\[
  -\gamma\beta t+\gamma x=0
  \Leftrightarrow x = \beta t
\]
which is exactly the origin moving along the positive $x$ axis with velocity $\beta$.

\section*{11b}
Taking the events to happen at the origin of the primed system,
\[
  \Lambda^{-1} \vec{x'}_{2}-\Lambda^{-1} \vec{x'}_{1}
  =
  \begin{pmatrix}
    \gamma t'_{2} \\
    \gamma\beta t'_{2} \\
    0 \\
    0
  \end{pmatrix}
  -
  \begin{pmatrix}
    \gamma t_{1} \\
    \gamma\beta t'_{1} \\
    0 \\
    0
  \end{pmatrix}
  =
  \begin{pmatrix}
    \gamma(t'_{2}-t'_{1}) \\
    \gamma\beta(t'_{1}-t'_{2}) \\
    0 \\
    0
  \end{pmatrix}
\]
The first component is $\gamma T$; since this is the computation of the difference between the two events in the unprimed frame,
this proves the time dilation formula.

\section*{11c}
A similar computation to the above result applies:
\[
  \Lambda^{-1}\vec{x_{2}'}-\Lambda^{-1}\vec{x_{1}'}
  =
  \begin{pmatrix}
    \gamma\beta x_{2}' \\
    \gamma x_{2}' \\
    0 \\
    0
  \end{pmatrix}
  -
  \begin{pmatrix}
    \gamma\beta x_{1}' \\
    \gamma x_{1}' \\
    0 \\
    0
  \end{pmatrix}
  =
  \begin{pmatrix}
    \gamma\beta L \\
    \gamma L \\
    0 \\
    0
  \end{pmatrix}
\]
Reading off the first component confirms the result.
Whichever occurs first along the $x$ axis occurs first in time, since $L$ is a distance and therefore positive.
For spacelike separated events,
\[
  \Lambda \vec{x_{2}}-\Lambda \vec{x_{1}}
  =
  \begin{pmatrix}
    \gamma t_{2}-\gamma\beta x_{2} - (\gamma t_{1}-\gamma\beta x_{1}) \\
    \gamma x_{2}-\gamma\beta t_{2} - (\gamma x_{1}-\gamma\beta t_{1}) \\
    0 \\
    0
  \end{pmatrix}
  =
  \begin{pmatrix}
    \gamma T-\gamma\beta L \\
    \gamma L - \gamma\beta T \\
    0 \\
    0
  \end{pmatrix}
\]
For the time component to be zero,
\[
  \gamma T=\gamma\beta L
  \Leftrightarrow \beta = \frac{T}{L}
\]
The spacelike condition ensures conformance with $|\beta|<1$:
\[
  T^{2}-L^{2}<0
  \Leftrightarrow T^{2}<L^{2}
  \Leftrightarrow |T|<|L|
  \Leftrightarrow \frac{|T|}{|L|}<1
  \Rightarrow |\beta| < 1
\]

\section*{11d}
Once again,
\[
  \Lambda^{-1}\vec{x_{2}'}-\Lambda^{-1}\vec{x_{1}'}
  =
  \begin{pmatrix}
    \gamma t_{2}+\gamma\beta x_{2}-(\gamma t_{1}+\gamma\beta x_{1}) \\
    \gamma\beta t_{2}+\gamma x_{2}-(\gamma\beta t_{1}+\gamma x_{1}) \\
    0 \\
    0
  \end{pmatrix}
  =
  \begin{pmatrix}
    \gamma T + \gamma\beta L \\
    \gamma \beta T + \gamma L \\
    0 \\
    0
  \end{pmatrix}
\]
The measurements are simultaneous in the unprimed frame, i.e. the first component of the above displacement is zero, yielding
$T=-\beta L$.
Plugging this in to the second component, one obtains
\[
  \gamma L-\gamma\beta^{2}L=L\gamma[1-\beta^{2}]=L\gamma(1/\gamma^{2})=L/\gamma
\]
as desired.

\section*{12}
For convenience of notation, define $f:SL(2,\mathbb{C})\to SO^{+}(1,3) :: A\mapsto (X\mapsto AXA^{\dagger})$ where $X$ is of the form
given in the problem.
This map is indeed a homomorphism: using $(AB)^{\dagger}=B^{\dagger}A^{\dagger}$,
\[
  f(A)f(B)=(X\mapsto AXA^{\dagger})\circ(X\mapsto BXB^{\dagger})=X\mapsto A(BXB^{\dagger})A^{\dagger}=(AB)x(B^{\dagger}A^{\dagger})
  =f(AB)
\]
The kernel of $f$ are those elements $A\in SL(2,\mathbb{C})$ such that $X=AXA^{\dagger}\Leftrightarrow A^{-1}X=XA^{\dagger}$ for all $X$ of
the given form.
Since $A\in SL(2,\mathbb{C})\Rightarrow \det A=1$ , $A$ is unitary, i.e. $AA^{\dagger}=A^{\dagger}A=I$.
We then can write
\[
  X=AXA^{\dagger}
  \Leftrightarrow XA=AXA^{\dagger}A
  \Leftrightarrow XA=AX
\]
Elements of the center of $GL(n,\mathbb{F})$ are $c^{*}I$ where $c^{*}$ is any unit of $\mathbb{F}$ and $I$ is the identity matrix, and
since the units in $\mathbb{R}$ are $\pm 1$, the kernel of the homomorphism is $\pm I$.
By the isomorphism theorem, $\im f\cong SL(2,\mathbb{C})/\ker f$, and $\ker f$ is discrete.
Since $\im f$ is isomorphic to a connected subgroup of the Lorentz group with the same dimension (since $\ker f$ is discrete), $\im f$ is isomorphic to the whole group,
implying $f$ is surjective.

\section*{13}
Using the fact $\tilde{x}$ is the difference of two observables and therefore Hermitian,
\[
  (\Delta x)^{2}(\Delta p)^{2}
  =\langle \psi|\tilde{x}^{2}|\psi \rangle\langle \psi|\tilde{p}^{2}|\psi \rangle
  =\langle \psi|\tilde{x}^{2}\psi \rangle\langle \psi|\tilde{p}^{2}\psi \rangle
  =\langle \tilde{x}\psi|\tilde{x}\psi \rangle\langle \tilde{p}\psi|\tilde{p}\psi \rangle
  \geq |\langle \tilde{x}\psi|\tilde{p}\psi \rangle|^{2}
  =|\langle \psi|\tilde{x}\tilde{p}\psi \rangle|^{2}
  =|\langle \psi|\tilde{x}\tilde{p}|\psi \rangle|^{2}
\]
We write
\[
  \langle\psi| \tilde{x}\tilde{p}|\psi\rangle
  =\langle\psi| \left( x-\langle \psi|x|\psi \rangle \right)\left( p-\langle \psi|p|\psi \rangle \right)|\psi\rangle
  =\langle\psi|xp|\psi\rangle-\langle\psi|x\langle \psi|p|\psi \rangle|\psi\rangle-\langle\psi|p\langle \psi|x|\psi
  \rangle|\psi\rangle+\langle \psi|x|\psi \rangle\langle \psi|p|\psi \rangle\langle \psi|\psi \rangle
\]
\[
  =\langle \psi|xp|\psi \rangle+\langle \psi|x|\psi \rangle\langle \psi|p|\psi \rangle
\]
Complex numbers have the property
\[
  |z|^{2}=(\Re z)^{2}+(\Im z)^{2}\geq (\Im z)^{2} = \left( \frac{1}{2i}(z-z^{*}) \right)^{2}
\]
Applying this to $z=\langle \psi|\tilde{x}\tilde{p}|\psi \rangle$,
\[
  |\langle \psi|\tilde{x}\tilde{p}|\psi \rangle|^{2}
  \geq \left( \frac{1}{2i}\left[ (\langle \psi|xp|\psi \rangle+\langle \psi|x|\psi \rangle\langle \psi|p|\psi \rangle)
      -(\langle \psi|xp|\psi \rangle+\langle \psi|x|\psi \rangle\langle \psi|p|\psi \rangle)^{*} \right] \right)^{2}
\]
\[
  =\left( \frac{1}{2i}\left[ \langle \psi|xp|\psi\rangle-\langle \psi|px|\psi \rangle \right] \right)^{2}
  =\left( \frac{1}{2i}\langle \psi|[x,p]|\psi \rangle \right)^{2}
  =\frac{1}{4}
  =\frac{\hbar^{2}}{4}
\]
where in the last equality we have returned from natural units.
The ground state of the simple harmonic oscillator is $\psi_{0}(x)=\left( \frac{m\omega}{\pi\hbar} \right)^{1/4}e^{-m\omega x^{2}/2\hbar}$,
from which we can compute
\[
  \langle \psi_{0}|x|\psi_{0}\rangle =0\textrm{ (odd function, symmetric interval)}
\]
\[
  \langle\psi_{0}|p|\psi_{0}  \rangle=\sqrt{\frac{m\omega}{\pi\hbar}}\int_{-\infty}^{\infty}e^{-m\omega x^{2}/2\hbar}
  \left(-i\hbar\frac{\partial}{\partial x}e^{-m\omega x^{2}/2\hbar}  \right)dx
  =\sqrt{\frac{m\omega}{\pi\hbar}}\int_{-\infty}^{\infty}e^{-m\omega x^{2}/2\hbar}\left( im\omega x e^{-m\omega x^{2}/2\hbar}\right)dx
\]
\[
  =0 \textrm{ (odd function, symmetric interval)}
\]
\[
  \Rightarrow \tilde{x}=x, \tilde{p}=p
\]
\[
  \Rightarrow (\Delta x)^{2}=\langle \psi_{0}|\tilde{x}^{2}|\psi_{0} \rangle=\langle \psi_{0}|x^{2}|\psi_{0} \rangle
  =\sqrt{\frac{m\omega}{\pi\hbar}}\int_{-\infty}^{\infty}e^{-m\omega x^{2}/2\hbar}x^{2}e^{-m\omega x^{2}/2\hbar}dx
\]
\[
  =\sqrt{\frac{m\omega}{\pi\hbar}}\int_{-\infty}^{\infty}x^{2}e^{-m\omega x^{2}/\hbar}
  =\sqrt{\frac{m\omega}{\pi\hbar}}\sqrt{\frac{\pi\hbar^{3}}{4m^{3}\omega^{3}}}
  =\sqrt{\frac{\hbar^{2}}{4m^{2}\omega^{2}}}=\frac{\hbar}{2m\omega}
\]
\[
  \Rightarrow (\Delta p)^{2}=\langle \psi_{0}|\tilde{p}^{2}|\psi_{0} \rangle=\langle \psi_{0}|p^{2}|\psi_{0} \rangle
  =-\sqrt{\frac{m\omega}{\pi\hbar}}\int_{-\infty}^{\infty}e^{-m\omega x^{2}/2\hbar}\hbar^{2}\frac{\partial^{2}}{\partial x^{2}}
  e^{-m\omega x^{2}/2\hbar}dx
\]
\[
  =-\sqrt{\frac{m\omega}{\pi\hbar}}\int_{-\infty}^{\infty}e^{-m\omega x^{2}/2\hbar}
  \hbar^{2}\left( \frac{1}{\hbar^{2}} m\omega e^{-m\omega x^{2}/2\hbar}(m\omega x^{2}-\hbar)\right)dx
\]
\[
  =-\sqrt{\frac{m\omega}{\pi\hbar}}\left( m^{2}\omega^{2}\int_{-\infty}^{\infty}x^{2}e^{-m\omega x^{2}/\hbar}dx
    -\hbar m\omega\int_{-\infty}^{\infty}e^{-m\omega x^{2}/\hbar}\right)
\]
\[
  =-\sqrt{\frac{m\omega}{\pi\hbar}}\left( m^{2}\omega^{2}\sqrt{\frac{\pi \hbar^{3}}{4m^{3}\omega^{3}}}
    -\hbar m\omega\sqrt{\frac{\pi\hbar}{m\omega}} \right)
  =-(\hbar m\omega/2-\hbar m\omega)=m\omega\frac{\hbar}{2}
\]
where we have used a table for the nasty Gaussian-type integrals.
Multiplying the results, we indeed confirm this is a minimum-uncertainty state:
\[
  (\Delta x)^{2}(\Delta p)^{2}=\frac{\hbar}{2m\omega}\left( m\omega\frac{\hbar}{2}\right)=\frac{\hbar^{2}}{4}
\]

\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
