:PROPERTIES:
:ID:       770eb735-9124-4b24-aae0-61539bbc2099
:END:
#+title: ROTTIE

* ROTTIE: the Root Of TrusT In Everything

** Problem

Knuth's classic Turing award lecture /Reflections on Trusting Trust/ illustrated a grave danger in the software development process: trusting compilers. After all, the compilers compile themselves these days; the assemblers are written in C, as are =readelf= and its cousins---it's expected one simply accepts the wisdom of those who designed those opaque tools, back in the dark ages, that seeded the bootstrapping process. Not only must one accept their wisdom, that those programs aren't stealthily propagating dangerous bugs down to humble user code, but also trust their benevolence. This is a much more disturbing proposition. What assurance does one have, as a mere mortal, that there were no ancients with malicious intent, implanting devious, self-propagating, self-concealing secret code in some punched-tape binary assembler in the '60s that would spread to every descendent system? One can't audit binaries, as the auditing tools may be just as compromised. One can't inspect processor state from another machine. GDB has the same trust issues. Worse still, one can't even look to history and find precise answers about exactly who and what you're trusting. Most of that has been lost to history; the software trust tree is essentially nearest-neighbor, with each programmer (eminently practical) knowing his tooling just enough to accomplish his objectives.

So, not only are we unable to trust anything precisely, we're unable to obtain a probabilistic confidence estimate, and even unable to enumerate exactly what it /is/ that we're trusting!

Knuth spoke of software. On a little reflection, it's immediately clear the same problem extends to hardware too: one must trust that disk flashing is correct, that the system runs the loaded boot code, that the screen is not altering displayed information. The #bootstrappable project has made admirable strides towards a minimal software bootstrap process for a POSIX system (numbers: I was told of roughly 1k in machine code, comprising a proto-assembler and an input-output-only shell running in UEFI, from which a source bootstrap process can occur). However, a modern system is made up of dozens of microcontrollers in addition to the CPU, from the disk to the keyboard to the display to the USB controller. These also are presumably compiled with a standard compiler, flashed with a standard system, and even their silicon designed on a standard system with a Verilog compiler written in standard C. This project is important and essential nonetheless, as this process will need to be done regardless, and reduction in attack surface is always welcome. But, it is incomplete nonetheless.

** Solution

Having considered these questions, it seems clear that there is no solution to this hardware-trusting-trust problem other than the construction of dedicated hardware, from which other hardware may be designed, bootstraps performed, silicon tested, instruments controlled, formal correctness proofs checked, or data algorithmically analyzed. The problem rears its head again should one use off-the-shelf CPUs, integrated circuits, EEPROMs, etc. Any conforming design should have correctness rooted in (meta)physical and epistemological propositions that are as simple as possible, e.g. "First-order logic+ZFC does not prove a contradiction," "Maxwell's equations describe electromagnetic phenomena," "the wire used behaves like wire," "this component used behaves like a transistor," etc.

I propose the construction of a mainframe-style computer called ROTTIE (Root Of TrusT In Everything), designed so as to ground this web of questions. It will be a PDP-1-style machine: discrete transistor logic, paper-tape input and output, magnetic-core memory, register state display, manual clocking, high-ish-voltage operation (to reduce cosmic-ray interference). Precise descriptions of its design, construction, and verification (precisely outlining the propositions on which its correctness depends, and attempting to argue their correctness and minimality) will be produced and distributed /in print/, for others to review and imitate as they so desire. The tooling used in the construction will be exclusively tech as least as trustworthy, i.e. all measurements of voltages and electrical characteristic checks must be done with vacuum-tube or discrete-component test equipment, with the design thereof distributed alongside the construction instructions. To take things to their fullest extent, one might want to do everything, from construction of power generation equipment to mining, extraction, and synthesis of wire and electrical components, onesself, and it might be desirable to at least include descriptions of that process, so that nothing falls from "thin air." Additionally, there may be information-theoretical arguments (and possible design elements on which such arguments could be predicated) that even /if/ some or all of the transistors were compromised and, say, running a full-blown computer in an SMD package, they could not adversely influence program execution, because they never obtain sufficient information about the state of a computation.

** Implementation

Its ISA will probably be a simple R32IMA (E? CSA?), with an expandable memory-management unit that allows hardware evolution (perhaps: a line printer, dumb terminal, IC photolithography, or a JTAG line to a DUT). DMA and interrupt controller would be nice.

Possibly faster way to make core is with rod memory: patent US3593324A. I can envision a jig which can do whole rows in a single motion.
